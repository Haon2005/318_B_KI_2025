[
  {
    "objectID": "vektor_embedding.html",
    "href": "vektor_embedding.html",
    "title": "Vektor-Embedding",
    "section": "",
    "text": "Erstmal ein kleiner Gag um darauf hinzuweisen, wie gut Sortieralgorithmen bereits funktionieren (nicht KI).",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Vektor-Embedding"
    ]
  },
  {
    "objectID": "vektor_embedding.html#wie-funktioniert-das",
    "href": "vektor_embedding.html#wie-funktioniert-das",
    "title": "Vektor-Embedding",
    "section": "Wie funktioniert das?",
    "text": "Wie funktioniert das?\nJeder Figur wird ein Vektor zugeordnet, die Einträge stehen für bestimmte Eigenschaften.\nDas heißt ein Vektor könnte z.B. so aussehen. \\[(Größe, Haarfarbe, real/fiktiv, Alter, ...)\\]\nMan sieht schnell die Einträge können unterschiedliche Formen/Definitionen haben, aber das Prinzip ist schnell verstanden.\n\n\n\n\n\n\nUmsetzung mit Python\n\n\n\n\n\nIm folgenden ein Beispiel Code, mit dem du ein bisschen die Grundidee von Vektor-Embedding testen kannst.\nDu kannst den Code ausführen nachdem du deine Werte eingegeben hast mit dem Run Symbol oben rechts.\nDu kannst auch gerne weitere Personen zum variablen-Dictionary hinzufügen, um zu sehen, wie sich die Ergebnisse ändern!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Vektor-Embedding"
    ]
  },
  {
    "objectID": "vektor_embedding.html#vom-menschen-zum-wort-vektoren-in-sprachmodellen",
    "href": "vektor_embedding.html#vom-menschen-zum-wort-vektoren-in-sprachmodellen",
    "title": "Vektor-Embedding",
    "section": "Vom Menschen zum Wort: Vektoren in Sprachmodellen",
    "text": "Vom Menschen zum Wort: Vektoren in Sprachmodellen\nDas Grundprinzip ist nun hoffentlich klar: Alles Mögliche ist mithilfe von vielen Eigenschaften als Vektor darstellbar und damit mathematisch vergleichbar. Ein Large Language Model (LLM) macht im Prinzip genau das – nur wendet es dieses Konzept auf Sprache an.\nStatt ganzer Wörter zerlegt ein LLM Text in kleinere Einheiten, sogenannte Tokens (diese sind so gewählt, dass sie einmalig sind). Ein Token kann ein ganzes Wort, ein Wortteil (wie “-ung”) oder ein Satzzeichen sein. Jedes dieser Tokens wird in einen Vektor umgewandelt.\nDie wahre Magie moderner LLMs (wie sie seit den Transformer-Modellen existieren) liegt darin, Kontext zu verstehen. Betrachten wir zwei Sätze:\n\n“A bat is flying around.” (Eine Fledermaus fliegt herum.)\n“I hit the ball with a bat.” (Ich habe den Ball mit einem Schläger geschlagen.)\n\nÄltere Systeme, wie die Online-Übersetzer der 2010er Jahre, hätten für “bat” in beiden Fällen denselben Vektor verwendet und oft falsche Übersetzungen geliefert. Ein modernes LLM hingegen analysiert die umliegenden Wörter (“flying”, “hit the ball”) und erzeugt für “bat” in jedem Satz einen unterschiedlichen Vektor. Der Vektor für “Fledermaus” liegt im Vektorraum dann näher an “Tier” und “fliegen”, während der Vektor für “Schläger” näher an “Sport” und “schlagen” liegt.\nDiese Fähigkeit, Wörter im Kontext zu verstehen, ist der entscheidende Durchbruch, der die heutigen beeindruckenden KI-Leistungen erst möglich macht. Wenn ein LLM dann Text erzeugt, wählt es auf Basis des bisherigen Kontexts das Token aus, dessen Vektor mathematisch am besten als Nächstes passt.\nWie diese Wahl funktioniert werden wird in Unterkapitel genauer betrachten.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Vektor-Embedding"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html",
    "href": "ki_philosophische_Sicht.html",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "",
    "text": "KI also Künstliche Intelligenz beinhaltet offensichtlich den Begriff der Intelligenz. Allein dieser ist kein simpler Begriff, was bedeutet Intelligenz? Fangen wir klassisch enzyklopädisch an.\nIntelligenz \\(\\rightarrow\\) inter legere (lat.)\nalso “zwischen” “lesen/wählen” kann also betrachtet werden als die Fähigkeit des Wählens zwischen Irgendetwas. Intelligenz ist meistens als Problemlösekompetenz beschrieben.\nAber zurück zum Thema, es geht darum inwiefern eine Maschine intelligent sein kann, hier gibt es echt viele Debatten \\(\\dots\\) ich hatte schon mindestens 3 Seminare zu Thematiken in diese Richtungen. * Machine Consciousness (Kurzgesagt die Frage, nach dem Bewusstsein von Menschen und Maschinen) * Determinismus vs. freier Wille (Viele sagen, ein Computer ist nicht “Intelligent”, da er niemals frei entscheiden kann) * strong vs. weak AI (auch wenn man einen Computer als “intelligent” betrachten mag, so doch niemals als menschlich intelligent)\n\n\n\n\n\n\nEin paar weiterführende Links\n\n\n\n\n\n\nEin geniales Beispiel der Bewusstseinsfrage spielt sich in “Star Trek: The Next Generation” Staffel 2 Episode 9 ab. (Snodgrass 1989)\n\n\nHintergrundwissen\n\nDazu vielleicht noch ein wenig Hintergrundwissen (falls TNG nicht bekannt). Die Serie spielt im 24.Jh. Data ist ein Androide und der Herr in Blau im Clip hat als Ziel Data auseinander zu bauen um weitere wie ihn zu erschaffen. Dies will Data nicht, es geht in diesem “Gerichtsprozess” darum, ob Data einen eigenen Willen äußern kann, oder er sich nicht dem Auseinanderbauen unterziehen muss, da er nicht anderes ist als ein Besitz der Sternenflotte.\n\nIm Grund könnte man hier auch Filme wie Terminator o.ä. verlinken, die Idee der “Superintelligenz” entspringt der Idee, dass sobald eine KI ein Bewusstsein erringt, sie von nichts mehr aufgehalten werden kann.\nDie Unterscheidung zwischen starker und schwacher KI (Strong vs. Weak AI) ist zentral in der KI-Philosophie und geht ebenfalls auf John Searle zurück.\n\nEine schwache KI (Weak AI, auch als narrow AI oder schwache KI bezeichnet) ist darauf ausgelegt, eine spezifische Aufgabe zu erfüllen. Sie simuliert intelligentes Verhalten, ohne jedoch ein echtes Bewusstsein oder Verständnis zu besitzen. Alle heute existierenden KI-Systeme fallen in diese Kategorie.\n\n\nBeispiel für schwache KI\n\nBeispiele hierfür sind KIs, die im Schach, Go oder Starcraft Weltmeister besiegt haben, aber auch Sprachassistenten wie Siri oder eben große Sprachmodelle wie ChatGPT. Sie sind extrem leistungsfähig in ihrem definierten Bereich (z.B. Sprache), aber sie “verstehen” nicht im menschlichen Sinne.\n\nEine starke KI (Strong AI) wäre eine Maschine, die nicht nur Intelligenz simuliert, sondern tatsächlich ein eigenes Bewusstsein, Verstand und Verständnis besitzt – vergleichbar mit einem Menschen. Eine solche KI würde nicht nur Aufgaben lösen, sondern auch subjektive Erfahrungen machen. Dieses Konzept ist rein hypothetisch und wird oft auch als Künstliche Allgemeine Intelligenz (AGI) bezeichnet.\n\n\nBeispiel für starke KI\n\nMan könnte jetzt sagen, aber ChatGPT und Co. sind das doch. NEIN, sind sie nicht. LLMs sind extrem fortgeschrittene schwache KIs. Sie können zwar eine beeindruckende Vielfalt an Aufgaben bewältigen, basieren aber auf Mustererkennung in Daten und besitzen kein Bewusstsein oder echte Intentionalität.\nEine echte starke KI, die sich ihrer selbst bewusst ist, existiert bisher nur in der Science-Fiction (wie z.B. Data aus Star Trek). Die Entwicklung einer solchen KI würde das Konzept der Superintelligenz aufwerfen – eine Intelligenz, die die menschliche in allen Aspekten weit übertrifft.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#grundlage",
    "href": "ki_philosophische_Sicht.html#grundlage",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "",
    "text": "KI also Künstliche Intelligenz beinhaltet offensichtlich den Begriff der Intelligenz. Allein dieser ist kein simpler Begriff, was bedeutet Intelligenz? Fangen wir klassisch enzyklopädisch an.\nIntelligenz \\(\\rightarrow\\) inter legere (lat.)\nalso “zwischen” “lesen/wählen” kann also betrachtet werden als die Fähigkeit des Wählens zwischen Irgendetwas. Intelligenz ist meistens als Problemlösekompetenz beschrieben.\nAber zurück zum Thema, es geht darum inwiefern eine Maschine intelligent sein kann, hier gibt es echt viele Debatten \\(\\dots\\) ich hatte schon mindestens 3 Seminare zu Thematiken in diese Richtungen. * Machine Consciousness (Kurzgesagt die Frage, nach dem Bewusstsein von Menschen und Maschinen) * Determinismus vs. freier Wille (Viele sagen, ein Computer ist nicht “Intelligent”, da er niemals frei entscheiden kann) * strong vs. weak AI (auch wenn man einen Computer als “intelligent” betrachten mag, so doch niemals als menschlich intelligent)\n\n\n\n\n\n\nEin paar weiterführende Links\n\n\n\n\n\n\nEin geniales Beispiel der Bewusstseinsfrage spielt sich in “Star Trek: The Next Generation” Staffel 2 Episode 9 ab. (Snodgrass 1989)\n\n\nHintergrundwissen\n\nDazu vielleicht noch ein wenig Hintergrundwissen (falls TNG nicht bekannt). Die Serie spielt im 24.Jh. Data ist ein Androide und der Herr in Blau im Clip hat als Ziel Data auseinander zu bauen um weitere wie ihn zu erschaffen. Dies will Data nicht, es geht in diesem “Gerichtsprozess” darum, ob Data einen eigenen Willen äußern kann, oder er sich nicht dem Auseinanderbauen unterziehen muss, da er nicht anderes ist als ein Besitz der Sternenflotte.\n\nIm Grund könnte man hier auch Filme wie Terminator o.ä. verlinken, die Idee der “Superintelligenz” entspringt der Idee, dass sobald eine KI ein Bewusstsein erringt, sie von nichts mehr aufgehalten werden kann.\nDie Unterscheidung zwischen starker und schwacher KI (Strong vs. Weak AI) ist zentral in der KI-Philosophie und geht ebenfalls auf John Searle zurück.\n\nEine schwache KI (Weak AI, auch als narrow AI oder schwache KI bezeichnet) ist darauf ausgelegt, eine spezifische Aufgabe zu erfüllen. Sie simuliert intelligentes Verhalten, ohne jedoch ein echtes Bewusstsein oder Verständnis zu besitzen. Alle heute existierenden KI-Systeme fallen in diese Kategorie.\n\n\nBeispiel für schwache KI\n\nBeispiele hierfür sind KIs, die im Schach, Go oder Starcraft Weltmeister besiegt haben, aber auch Sprachassistenten wie Siri oder eben große Sprachmodelle wie ChatGPT. Sie sind extrem leistungsfähig in ihrem definierten Bereich (z.B. Sprache), aber sie “verstehen” nicht im menschlichen Sinne.\n\nEine starke KI (Strong AI) wäre eine Maschine, die nicht nur Intelligenz simuliert, sondern tatsächlich ein eigenes Bewusstsein, Verstand und Verständnis besitzt – vergleichbar mit einem Menschen. Eine solche KI würde nicht nur Aufgaben lösen, sondern auch subjektive Erfahrungen machen. Dieses Konzept ist rein hypothetisch und wird oft auch als Künstliche Allgemeine Intelligenz (AGI) bezeichnet.\n\n\nBeispiel für starke KI\n\nMan könnte jetzt sagen, aber ChatGPT und Co. sind das doch. NEIN, sind sie nicht. LLMs sind extrem fortgeschrittene schwache KIs. Sie können zwar eine beeindruckende Vielfalt an Aufgaben bewältigen, basieren aber auf Mustererkennung in Daten und besitzen kein Bewusstsein oder echte Intentionalität.\nEine echte starke KI, die sich ihrer selbst bewusst ist, existiert bisher nur in der Science-Fiction (wie z.B. Data aus Star Trek). Die Entwicklung einer solchen KI würde das Konzept der Superintelligenz aufwerfen – eine Intelligenz, die die menschliche in allen Aspekten weit übertrifft.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#das-chinese-room-experiment",
    "href": "ki_philosophische_Sicht.html#das-chinese-room-experiment",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Das Chinese-Room-Experiment",
    "text": "Das Chinese-Room-Experiment\nDas Gedankenexperiment des “Chinesischen Zimmers” wurde 1980 vom Philosophen John Searle vorgestellt (Searle 1980). Es ist das zentrale Argument gegen die Möglichkeit von starker KI und fragt, ob eine Maschine wirklich “verstehen” kann oder nur so tut, als ob.\nStell dir Folgendes vor:\n\nEine Person, die kein Wort Chinesisch spricht, sitzt allein in einem geschlossenen Raum.\nDurch einen Schlitz werden ihr Zettel mit chinesischen Schriftzeichen (Fragen) gereicht.\nIm Raum befindet sich ein riesiges Regelbuch auf Deutsch. In diesem Buch steht genau, welche chinesischen Schriftzeichen (Antworten) sie als Reaktion auf die hereingereichten Zeichen (Fragen) nach draußen geben soll.\nDie Person folgt den Anweisungen, sucht die passenden Symbole und gibt sie als Antwort zurück.\n\nFür einen Beobachter von außen, der Chinesisch spricht, sieht es so aus, als würde die Person im Raum die Fragen perfekt verstehen und beantworten.\nSearles Schlussfolgerung: Die Person im Raum hat absolut kein Verständnis für Chinesisch. Sie manipuliert lediglich Symbole basierend auf einem Regelwerk. Searle argumentiert, dass Computer genauso arbeiten. Selbst wenn eine KI perfekte Antworten gibt, bedeutet das nicht, dass sie ein echtes Bewusstsein oder Verständnis hat. Sie simuliert nur Intelligenz.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#turing-test",
    "href": "ki_philosophische_Sicht.html#turing-test",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Turing-Test",
    "text": "Turing-Test\nDer Turing-Test, vorgeschlagen von Alan Turing im Jahr 1950, ist eines der ältesten und berühmtesten Kriterien, um maschinelle Intelligenz zu bewerten (Turing 1950). Die Idee ist ein “Imitationsspiel”:\n\nEin menschlicher Fragesteller (C) kommuniziert über Textnachrichten mit zwei ihm unbekannten Gesprächspartnern.\nEiner der Gesprächspartner ist ein Mensch (B), der andere eine Maschine (A).\nDer Fragesteller muss herausfinden, wer von beiden die Maschine ist.\n\nWann besteht die Maschine den Test? Wenn der Fragesteller nach einer angemessenen Zeit nicht zuverlässig sagen kann, wer der Mensch und wer die Maschine ist, hat die Maschine den Turing-Test bestanden. Sie gilt dann als intelligent, weil ihr Verhalten von menschlichem Verhalten nicht zu unterscheiden ist.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#moderne-benchmark-tests",
    "href": "ki_philosophische_Sicht.html#moderne-benchmark-tests",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Moderne Benchmark Tests",
    "text": "Moderne Benchmark Tests\nDer klassische Turing-Test gilt heute in vielen Fällen als überholt, da moderne LLMs ihn oft problemlos bestehen können. Die Fähigkeit, eine menschliche Konversation zu imitieren, ist nicht mehr der alleinige Maßstab für fortgeschrittene KI.\n\n\n\n\n\n\nHinweis!\n\n\n\n\n\nAuch wenn man sich in der wissenschaftlichen Welt sehr einig ist, dass LLms den Turing Test bestehen können, heißt es nicht, dass irgendeine System den erkenntlich bestanden hat!\nDas erschafft dann nämlich ein ganz großes neues Problem wofür Firmen wie Google Philosophen anstellen um es zu verhindern.\nSollte es so sein, dass eine Maschine den Turing Test bestehe, so wäre sie laut einer sehr anerkannten Theorie intelligent. Das würde aber auch heißen eine Maschine zu nutzen, um z.B. Hausaufgaben etc. zu lösen wäre praktisch Sklaverei, dass klingt absurd, aber was trennt das eine vom Anderen?\nWas macht ein Kinderarbeit Kinderarbeit, warum ist es schlimm wenn Menschen ohne Bezahlung arbeiten?\nWarum sollte es gut sein, dass einem Intelligenten System der freie Wille genommen wird?\n\n\n\nZurück zum Thema, heutzutage werden daher andere Arten von Zielen versucht zu erreichen:\n\nIMO (Internationale Mathematik-Olympiade): Lange Zeit galt das Lösen von Problemen auf dem Niveau der IMO als eine große Hürde für KIs. Diese Aufgaben erfordern nicht nur Rechenleistung, sondern auch Kreativität und tiefes logisches Verständnis. Inzwischen gibt es KI-Systeme, die auch hier erstaunliche Leistungen erzielen und Goldmedaillen-Niveau erreichen.\nMMLU (Massive Multitask Language Understanding): Dies ist einer der aktuell gängigsten Benchmarks. Anstatt nur Konversation zu testen, prüft MMLU das Wissen und die Problemlösefähigkeiten einer KI in 57 verschiedenen Fachgebieten – darunter Mathematik, US-Geschichte, Jura, Informatik und mehr. Eine hohe Punktzahl im MMLU-Benchmark zeigt, dass ein Modell über ein breites und tiefes “Wissen” verfügt, das weit über das Führen eines einfachen Gesprächs hinausgeht.\n\n\n\n\nEine Übersicht über Fähigkeit von LLM Anfang 2025\n\n\nHierbei ist wichtig zu beachten, die Modelle die ein wenig aktueller sind, als die unten aufgelisteten haben alle beim IMO Test inzwischen auch 100% erreicht.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#zusammenfassung",
    "href": "ki_philosophische_Sicht.html#zusammenfassung",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Zusammenfassung",
    "text": "Zusammenfassung\nAus der Philosophischen Perspektive wird KI im Allgemeinen nicht als Intelligenz oder als bei Bewusstsein bezeichnet, hier vertrauen die meisten der Technischen Sicht und gehen davon aus, dass ein Programm egal wie komplex es ist kein Bewusstsein als solches entwickeln kann.\nEs ist jedoch leider auch strittig was überhaupt ein Bewusstsein ausmacht (Siehe den Star Trek Clip).\nVor 50-100 Jahren ging man offiziell davon aus, dass Tiere keinen Schmerz fühlen können und deswegen bei Operationen nicht betäubt werden müssen, sie haben ja kein Bewusstsein.\nDas sie mindestens irgendeine Form von Verstand haben ist inzwischen klar, aber ab wann ein Verstand, oder Bewusstsein schützenswert ist, ist weiterhin sehr umstritten (Siehe die Behandlung von Affen). Daher wird wohl selbst, falls es unstrittig bewusste KI geben sollte, nicht dazu kommen, dass diese verboten wird.\nUnd hoffentlich auch nicht dazu, dass sie uns als Superintelligenz direkt ausrottet :P",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "begruessung.html",
    "href": "begruessung.html",
    "title": "Alles Gute zum Geburtstag!",
    "section": "",
    "text": "Ich wünsche dir alles gut zu deinem 59. Geburtstag!\n\n\nIch habe dir hoffentlich bereits alles gute zum beginnenden 60ten Lebensjahr gewünscht, aber hier erneut alles herzlich gute zum Geburtstag.\nIch dachte mir einer Person, die sich alles holen kann was sie will, der kann man am ehesten Zeit schenken. Also dachte ich mir, worüber haben wir schon häufiger geredet, womit wolltest du dich beschäftigen, hast aber vermutlich noch keine Zeit dafür gefunden?\nRichtig AI ach ne KI hmm GPT oder LLM was ist denn da jetzt eigentlich der richtige Begriff, darum und darum was das alles eigentlich ist, was das bedeutet, wie man es definiert und auch was das ganze moralisch ethisch an Problemen darstellt, darum soll es auf dieser kleinen Webseite für dich gehen.\n\n\n\n\n\n\nEin paar Hinweise\n\n\n\n\n\n\nEs wird auf dieser Webseite immer mal wieder ein paar kleine “Callout” Blöcke wie diesen geben, ich werde damit ein wenig versuchen die Webseite lesbarer zu gestalten und evtl. schon vorhandenes Vorwissen in solchen Blöcken zu verstecken, damit falls du das bereits kennst du es leicht ignorieren kannst.\n\n\n\nAuch solche Blöcke wird es teilweise Drücke hier \\(\\leftarrow\\)\n\nDiese Blöcke werde ich auch manchmal nutzen, da sie ein wenig subtiler sind um Inhalte zu verschachteln.\n\nSteuerung der Webseite - Wie oben zu sehen gibt es zum einen … - Platzhalter!\n\n\n\nVon jetzt an also gut Klick und Lern!",
    "crumbs": [
      "Begrüßung",
      "Willkommen & Gratulation"
    ]
  },
  {
    "objectID": "ki_allgemein.html",
    "href": "ki_allgemein.html",
    "title": "KI im Allgemeinen",
    "section": "",
    "text": "Mit KI und LLMs wird seit etwa dem 2ten Weltkrieg geforscht, auch (Turing 1950) ist daran beteiligt.\nÜber die Jahrzehnte hat sich einiges getan, aber wie den meisten aufgefallen ist ist “plötzlich KI überall”, das lässt sich ein bisschen in dem folgenden Bild erkennen:\n (Wang et al. 2024)\nDas liegt vor allem an (Vaswani et al. 2017) in dem verlinkten Paper “Attention is all you need” von 2017, wird ein wichtiger Anstoß gegeben der die Grundlage legt für alle modernen LLMs, das Transformer Modell.\n\n\nJA die Daten 2015 und 2017 passen nicht klicke hier für mehr Informationen\n\nDas Paper von (Vaswani et al. 2017) ist zwar nicht Ursprung des Attention Algorithmus, aber es nutzt diese Idee von 2014 um das Transformer Modell zu entwickeln.\nAls kleiner Nebenhinweis “GPT” ist vermutlich ein Begriff, steht für “Generative Pre-trained Transformer”. Daran kann man evtl. erkennen wie wichtig dieses Paper ist. Die relevanteste KI der heutigen Tage hat es im Namen stehen.",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#historie",
    "href": "ki_allgemein.html#historie",
    "title": "KI im Allgemeinen",
    "section": "",
    "text": "Mit KI und LLMs wird seit etwa dem 2ten Weltkrieg geforscht, auch (Turing 1950) ist daran beteiligt.\nÜber die Jahrzehnte hat sich einiges getan, aber wie den meisten aufgefallen ist ist “plötzlich KI überall”, das lässt sich ein bisschen in dem folgenden Bild erkennen:\n (Wang et al. 2024)\nDas liegt vor allem an (Vaswani et al. 2017) in dem verlinkten Paper “Attention is all you need” von 2017, wird ein wichtiger Anstoß gegeben der die Grundlage legt für alle modernen LLMs, das Transformer Modell.\n\n\nJA die Daten 2015 und 2017 passen nicht klicke hier für mehr Informationen\n\nDas Paper von (Vaswani et al. 2017) ist zwar nicht Ursprung des Attention Algorithmus, aber es nutzt diese Idee von 2014 um das Transformer Modell zu entwickeln.\nAls kleiner Nebenhinweis “GPT” ist vermutlich ein Begriff, steht für “Generative Pre-trained Transformer”. Daran kann man evtl. erkennen wie wichtig dieses Paper ist. Die relevanteste KI der heutigen Tage hat es im Namen stehen.",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#einführung",
    "href": "ki_allgemein.html#einführung",
    "title": "KI im Allgemeinen",
    "section": "Einführung",
    "text": "Einführung\nKünstliche Intelligenz (KI) beschreibt Maschinen oder Software welche so gestaltet wurde, dass sie Aufgaben übernehmen, die üblicherweise menschliche Intelligenz erfordern. Dazu gehören Wahrnehmung, Sprachverstehen, Planen, Lernen und Problemlösen.\n\nAn AI system is a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment.\n\n— (“OECD AI Principles” 2019)",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#hauptansätze-der-ki",
    "href": "ki_allgemein.html#hauptansätze-der-ki",
    "title": "KI im Allgemeinen",
    "section": "Hauptansätze der KI",
    "text": "Hauptansätze der KI\nKünstliche Intelligenz ist kein monolithisches Feld, sondern unterteilt sich in verschiedene Ansätze und Techniken. Die wichtigsten davon werden hier vorgestellt.\n\nSymbolische KIMaschinelles Lernen (ML)Deep LearningNeuronale Netze\n\n\nSymbolische KI (auch „Good Old-Fashioned AI“) basiert auf Regeln, Logik und Wissensrepräsentation. Entwickler definieren explizit das Wissen und die Regeln, nach denen das System Entscheidungen trifft.\n\nFunktionsweise: Arbeitet mit Symbolen und logischen “Wenn-Dann”-Regeln.\nVorteil: Die Entscheidungen sind transparent und nachvollziehbar.\nNachteil: Sehr starr und schlecht skalierbar für komplexe, unstrukturierte Probleme wie Bild- oder Spracherkennung.\n\nFür weiteres: (“Symbolic Artificial Intelligence — Wikipedia” 2025)\n\n\nBeim maschinellen Lernen (ML) werden die Regeln nicht fest programmiert. Stattdessen lernt ein Algorithmus aus Daten, Muster zu erkennen und Vorhersagen zu treffen. Es ist der am weitesten verbreitete Ansatz in der modernen KI.\nMan unterscheidet hauptsächlich drei Arten:\n\nÜberwachtes Lernen (Supervised Learning): Das Modell lernt von Daten, die bereits mit der richtigen Antwort (“Label”) versehen sind (z.B. Bilder von Katzen mit dem Label “Katze”).\nUnüberwachtes Lernen (Unsupervised Learning): Das Modell findet eigenständig Muster und Strukturen in ungelabelten Daten (z.B. Kundensegmentierung).\nVerstärkendes Lernen (Reinforcement Learning): Ein “Agent” lernt durch Versuch und Irrtum, indem er für gute Aktionen belohnt und für schlechte bestraft wird (z.B. beim Training einer KI für ein Brettspiel).\n\n\n\n\n\n\n\nEin kleiner Grundriss (Ein Vortrag, den ich dazu mal gehalten habe)\n\n\n\n\n\n\n\nIhr Browser unterstützt keine eingebetteten PDFs. Sie können es stattdessen hier herunterladen.\n\n\nBei Fragen zu dem Vortrag, frag mich gerne :D\n\n\n\nFür weiteres: ((Kochenderfer et al. 2020),(“Machine Learning — Wikipedia” 2025))\n\n\nDeep Learning ist ein Teilgebiet des maschinellen Lernens, das besonders tiefe (im Sinne von viele Lagen hintereinander) neuronale Netze verwendet. Diese Tiefe ermöglicht es dem Modell, sehr komplexe und hierarchische Merkmale aus den Daten zu lernen.\n\nMerkmalshierarchie: Die ersten Schichten erkennen einfache Merkmale (z.B. Kanten in einem Bild), während tiefere Schichten diese zu komplexeren Konzepten (z.B. Augen, Gesichter) zusammensetzen.\nAnwendungen: Fast alle modernen Durchbrüche wie Bilderkennung, Sprachübersetzung (Google Translate) und selbstfahrende Autos basieren auf Deep Learning. LLMs sind ebenfalls eine Form des Deep Learning.\n\nFür weiteres: ((LeCun, Bengio, and Hinton 2015),(“Deep Learning — Wikipedia” 2025))\n\n\nNeuronale Netze sind das Herzstück des Deep Learning. Sie sind von der Struktur des menschlichen Gehirns inspiriert und bestehen aus miteinander verbundenen “Neuronen”, die in Schichten (Layern) angeordnet sind.\n\nAufbau: Jedes Neuron empfängt Signale, verarbeitet sie und gibt ein eigenes Signal an die nächste Schicht weiter. Die Verbindungen zwischen den Neuronen haben “Gewichte”, die im Lernprozess angepasst werden.\nFunktion: Durch die Anpassung dieser Gewichte lernt das Netz, komplexe Muster in den Daten zu erkennen – zum Beispiel die Pixelmuster, die eine Katze auf einem Bild ausmachen.\n\nEin fantastisches Video, das die Grundlagen visuell erklärt, ist von 3Blue1Brown: (Sanderson 2017)",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#anwendungsbereiche",
    "href": "ki_allgemein.html#anwendungsbereiche",
    "title": "KI im Allgemeinen",
    "section": "Anwendungsbereiche",
    "text": "Anwendungsbereiche\nNachdem hoffentlich ein wenig klar geworden ist, wie KI funktioniert ein bisschen dazu, wie sie meist verwendet wird.\nMeist Bekannt ist die Variante mit Large-Language-Models (LLMs).",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#aber-auch-gesichtserkennung-o.ä.-arbeitet-mithilfe-von-ki",
    "href": "ki_allgemein.html#aber-auch-gesichtserkennung-o.ä.-arbeitet-mithilfe-von-ki",
    "title": "KI im Allgemeinen",
    "section": "Aber auch Gesichtserkennung o.ä. arbeitet mithilfe von KI",
    "text": "Aber auch Gesichtserkennung o.ä. arbeitet mithilfe von KI",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#vertiefungsmöglichkeiten",
    "href": "ki_allgemein.html#vertiefungsmöglichkeiten",
    "title": "KI im Allgemeinen",
    "section": "Vertiefungsmöglichkeiten:",
    "text": "Vertiefungsmöglichkeiten:\nUnd auch an sich für ein paar SEHR gut zusammenfassende You-Tube Videos (die an unterschiedlichen Unis von Dozenten empfohlen werden):\nEinmal im Allgemeinen der Kanal 3blue1brown Aber auch die folgenden Spezifischen Videos:\n- Video zu Neuronalen Netzen: - Video dazu wie ein Neuronales Netz lernen: - Video zum Attention Mechanismus:\nOder ((“OECD AI Principles” 2019),(“AI Index Report — Stanford HAI” 2025))",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "konzept_llm.html",
    "href": "konzept_llm.html",
    "title": "LLM- das Grundkonzept",
    "section": "",
    "text": "Besser als ich es erklären kann, wird es im Zweifel hier von 3blue1brown auf Youtube erklärt, aber ich werde mich mal dran versuchen.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  },
  {
    "objectID": "konzept_llm.html#was-ist-ein-llm",
    "href": "konzept_llm.html#was-ist-ein-llm",
    "title": "LLM- das Grundkonzept",
    "section": "Was ist ein LLM?",
    "text": "Was ist ein LLM?\nEin Large Language Model (LLM), ein großes Sprachmodell zu Deutsch, ist eine Art von künstlicher Intelligenz, die darauf trainiert ist, menschliche Sprache zu verstehen und zu erzeugen. Man kann es sich als ein extrem großes neuronales Netz vorstellen, das mit einer gigantischen Menge an Textdaten (wie Büchern und großen Teilen des Internets) trainiert wurde. Das Hauptziel eines LLM ist es, auf eine Texteingabe (einen “Prompt”) eine sinnvolle und kontextbezogene textliche Antwort zu generieren. Bekannte Beispiele sind die Modelle der GPT-Reihe (die hinter ChatGPT stehen), Googles Gemini oder Metas Llama.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  },
  {
    "objectID": "konzept_llm.html#wie-funktioniert-ein-llm",
    "href": "konzept_llm.html#wie-funktioniert-ein-llm",
    "title": "LLM- das Grundkonzept",
    "section": "Wie funktioniert ein LLM",
    "text": "Wie funktioniert ein LLM\nDie Funktionsweise eines LLM lässt sich vereinfacht in zwei Hauptphasen unterteilen: das Training und die Anwendung (auch Inferenz genannt).\n\nPhase 1: Das Training (Lernphase)\n\nDaten: Das Modell wird mit riesigen Mengen an Texten gefüttert.\nZiel: Die Kernaufgabe während des Trainings ist simpel, aber wirkungsvoll: “Sage das nächste Wort voraus.” Das Modell bekommt einen Satzanfang und versucht, das wahrscheinlichste nächste Wort zu erraten.\nLernprozess: Bei jeder falschen Vorhersage passt es seine internen Parameter an. Durch milliardenfache Wiederholung lernt es so Grammatik, Fakten, Zusammenhänge und sogar Argumentationsstile. Es entwickelt ein statistisches “Verständnis” von Sprache.\n\nPhase 2: Die Anwendung (Inferenz)\n\nEingabe: Du gibst eine Frage oder einen Befehl ein (der “Prompt”).\nGenerierung: Basierend auf deinem Prompt und seinem Training berechnet das LLM das wahrscheinlichste erste Wort der Antwort.\nWort für Wort: Dieses neue Wort wird an die bisherige Konversation angehängt, und der Prozess wiederholt sich: Das Modell berechnet das nächste wahrscheinlichste Wort, dann das übernächste und so weiter, bis eine vollständige Antwort entstanden ist.\n\n\nEs ist also kein einfaches Nachschlagen in einer Datenbank, sondern ein kreativer, statistischer Prozess der Texterzeugung.\nUm die Funktionsweise besser zu verstehen, solltest du dir die nächsten Kapitel durchlesen. Dort wird erklärt, wie ein LLM Wörter überhaupt mathematisch versteht (Vektor-Embedding) und wie es im Detail aufgebaut ist.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  },
  {
    "objectID": "konzept_llm.html#weiterführende-quellen",
    "href": "konzept_llm.html#weiterführende-quellen",
    "title": "LLM- das Grundkonzept",
    "section": "Weiterführende Quellen",
    "text": "Weiterführende Quellen\nEine komprimierte Übersicht über Large Language Models wird angeboten von [@naveed2024comprehensiveoverviewlargelanguage]",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  }
]