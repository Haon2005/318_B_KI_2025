[
  {
    "objectID": "vektor_embedding.html",
    "href": "vektor_embedding.html",
    "title": "Vektor-Embedding",
    "section": "",
    "text": "Erstmal ein kleiner Gag um darauf hinzuweisen, wie gut Sortieralgorithmen bereits funktionieren (nicht KI).\nEin beliebtes Spiel in meiner Schulzeit war der Akinator\n\\(\\rightarrow\\) Klicke bitte auf Spielen in der Mitte \\(\\leftarrow\\)",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Vektor-Embedding"
    ]
  },
  {
    "objectID": "vektor_embedding.html#wie-funktioniert-das",
    "href": "vektor_embedding.html#wie-funktioniert-das",
    "title": "Vektor-Embedding",
    "section": "Wie funktioniert das?",
    "text": "Wie funktioniert das?\nJeder Figur wird ein Vektor zugeordnet, die Einträge stehen für bestimmte Eigenschaften.\nDas heißt ein Vektor könnte z.B. so aussehen. \\[(Größe, Haarfarbe, real/fiktiv, Alter, ...)\\]\nMan sieht schnell die Einträge können unterschiedliche Formen/Definitionen haben, aber das Prinzip ist schnell verstanden.\n\n\n\n\n\n\nUmsetzung mit Python\n\n\n\n\n\nIm folgenden ein Beispiel Code, mit dem du ein bisschen die Grundidee von Vektor-Embedding testen kannst.\nDu kannst den Code ausführen nachdem du deine Werte eingegeben hast mit dem Run Symbol oben rechts.\nDu kannst auch gerne weitere Personen zum variablen-Dictionary hinzufügen, um zu sehen, wie sich die Ergebnisse ändern!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Vektor-Embedding"
    ]
  },
  {
    "objectID": "vektor_embedding.html#vom-menschen-zum-wort-vektoren-in-sprachmodellen",
    "href": "vektor_embedding.html#vom-menschen-zum-wort-vektoren-in-sprachmodellen",
    "title": "Vektor-Embedding",
    "section": "Vom Menschen zum Wort: Vektoren in Sprachmodellen",
    "text": "Vom Menschen zum Wort: Vektoren in Sprachmodellen\nDas Grundprinzip ist nun hoffentlich klar: Alles Mögliche ist mithilfe von vielen Eigenschaften als Vektor darstellbar und damit mathematisch vergleichbar. Ein Large Language Model (LLM) macht im Prinzip genau das – nur wendet es dieses Konzept auf Sprache an.\nStatt ganzer Wörter zerlegt ein LLM Text in kleinere Einheiten, sogenannte Tokens (diese sind so gewählt, dass sie einmalig sind). Ein Token kann ein ganzes Wort, ein Wortteil (wie “-ung”) oder ein Satzzeichen sein. Jedes dieser Tokens wird in einen Vektor umgewandelt.\nDie wahre Magie moderner LLMs (wie sie seit den Transformer-Modellen existieren) liegt darin, Kontext zu verstehen. Betrachten wir zwei Sätze:\n\n“A bat is flying around.” (Eine Fledermaus fliegt herum.)\n“I hit the ball with a bat.” (Ich habe den Ball mit einem Schläger geschlagen.)\n\nÄltere Systeme, wie die Online-Übersetzer der 2010er Jahre, hätten für “bat” in beiden Fällen denselben Vektor verwendet und oft falsche Übersetzungen geliefert. Ein modernes LLM hingegen analysiert die umliegenden Wörter (“flying”, “hit the ball”) und erzeugt für “bat” in jedem Satz einen unterschiedlichen Vektor. Der Vektor für “Fledermaus” liegt im Vektorraum dann näher an “Tier” und “fliegen”, während der Vektor für “Schläger” näher an “Sport” und “schlagen” liegt.\nDiese Fähigkeit, Wörter im Kontext zu verstehen, ist der entscheidende Durchbruch, der die heutigen beeindruckenden KI-Leistungen erst möglich macht. Wenn ein LLM dann Text erzeugt, wählt es auf Basis des bisherigen Kontexts das Token aus, dessen Vektor mathematisch am besten als Nächstes passt.\nWie diese Wahl funktioniert werden wird in Unterkapitel genauer betrachten.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Vektor-Embedding"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html",
    "href": "ki_philosophische_Sicht.html",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "",
    "text": "KI also Künstliche Intelligenz beinhaltet offensichtlich den Begriff der Intelligenz. Allein dieser ist kein simpler Begriff, was bedeutet Intelligenz? Fangen wir klassisch enzyklopädisch an.\nIntelligenz \\(\\rightarrow\\) inter legere (lat.)\nalso “zwischen” “lesen/wählen” kann also betrachtet werden als die Fähigkeit des Wählens zwischen Irgendetwas. Intelligenz ist meistens als Problemlösekompetenz beschrieben.\nAber zurück zum Thema, es geht darum inwiefern eine Maschine intelligent sein kann, hier gibt es echt viele Debatten \\(\\dots\\) ich hatte schon mindestens 3 Seminare zu Thematiken in diese Richtungen. * Machine Consciousness (Kurzgesagt die Frage, nach dem Bewusstsein von Menschen und Maschinen) * Determinismus vs. freier Wille (Viele sagen, ein Computer ist nicht “Intelligent”, da er niemals frei entscheiden kann) * strong vs. weak AI (auch wenn man einen Computer als “intelligent” betrachten mag, so doch niemals als menschlich intelligent)\n\n\n\n\n\n\nEin paar weiterführende Links\n\n\n\n\n\n\nEin geniales Beispiel der Bewusstseinsfrage spielt sich in “Star Trek: The Next Generation” Staffel 2 Episode 9 ab. (Snodgrass 1989)\n\n\nHintergrundwissen\n\nDazu vielleicht noch ein wenig Hintergrundwissen (falls TNG nicht bekannt). Die Serie spielt im 24.Jh. Data ist ein Androide und der Herr in Blau im Clip hat als Ziel Data auseinander zu bauen um weitere wie ihn zu erschaffen. Dies will Data nicht, es geht in diesem “Gerichtsprozess” darum, ob Data einen eigenen Willen äußern kann, oder er sich nicht dem Auseinanderbauen unterziehen muss, da er nicht anderes ist als ein Besitz der Sternenflotte.\n\nIm Grund könnte man hier auch Filme wie Terminator o.ä. verlinken, die Idee der “Superintelligenz” entspringt der Idee, dass sobald eine KI ein Bewusstsein erringt, sie von nichts mehr aufgehalten werden kann.\nDie Unterscheidung zwischen starker und schwacher KI (Strong vs. Weak AI) ist zentral in der KI-Philosophie und geht ebenfalls auf John Searle zurück.\n\nEine schwache KI (Weak AI, auch als narrow AI oder schwache KI bezeichnet) ist darauf ausgelegt, eine spezifische Aufgabe zu erfüllen. Sie simuliert intelligentes Verhalten, ohne jedoch ein echtes Bewusstsein oder Verständnis zu besitzen. Alle heute existierenden KI-Systeme fallen in diese Kategorie.\n\n\nBeispiel für schwache KI\n\nBeispiele hierfür sind KIs, die im Schach, Go oder Starcraft Weltmeister besiegt haben, aber auch Sprachassistenten wie Siri oder eben große Sprachmodelle wie ChatGPT. Sie sind extrem leistungsfähig in ihrem definierten Bereich (z.B. Sprache), aber sie “verstehen” nicht im menschlichen Sinne.\n\nEine starke KI (Strong AI) wäre eine Maschine, die nicht nur Intelligenz simuliert, sondern tatsächlich ein eigenes Bewusstsein, Verstand und Verständnis besitzt – vergleichbar mit einem Menschen. Eine solche KI würde nicht nur Aufgaben lösen, sondern auch subjektive Erfahrungen machen. Dieses Konzept ist rein hypothetisch und wird oft auch als Künstliche Allgemeine Intelligenz (AGI) bezeichnet.\n\n\nBeispiel für starke KI\n\nMan könnte jetzt sagen, aber ChatGPT und Co. sind das doch. NEIN, sind sie nicht. LLMs sind extrem fortgeschrittene schwache KIs. Sie können zwar eine beeindruckende Vielfalt an Aufgaben bewältigen, basieren aber auf Mustererkennung in Daten und besitzen kein Bewusstsein oder echte Intentionalität.\nEine echte starke KI, die sich ihrer selbst bewusst ist, existiert bisher nur in der Science-Fiction (wie z.B. Data aus Star Trek). Die Entwicklung einer solchen KI würde das Konzept der Superintelligenz aufwerfen – eine Intelligenz, die die menschliche in allen Aspekten weit übertrifft.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#grundlage",
    "href": "ki_philosophische_Sicht.html#grundlage",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "",
    "text": "KI also Künstliche Intelligenz beinhaltet offensichtlich den Begriff der Intelligenz. Allein dieser ist kein simpler Begriff, was bedeutet Intelligenz? Fangen wir klassisch enzyklopädisch an.\nIntelligenz \\(\\rightarrow\\) inter legere (lat.)\nalso “zwischen” “lesen/wählen” kann also betrachtet werden als die Fähigkeit des Wählens zwischen Irgendetwas. Intelligenz ist meistens als Problemlösekompetenz beschrieben.\nAber zurück zum Thema, es geht darum inwiefern eine Maschine intelligent sein kann, hier gibt es echt viele Debatten \\(\\dots\\) ich hatte schon mindestens 3 Seminare zu Thematiken in diese Richtungen. * Machine Consciousness (Kurzgesagt die Frage, nach dem Bewusstsein von Menschen und Maschinen) * Determinismus vs. freier Wille (Viele sagen, ein Computer ist nicht “Intelligent”, da er niemals frei entscheiden kann) * strong vs. weak AI (auch wenn man einen Computer als “intelligent” betrachten mag, so doch niemals als menschlich intelligent)\n\n\n\n\n\n\nEin paar weiterführende Links\n\n\n\n\n\n\nEin geniales Beispiel der Bewusstseinsfrage spielt sich in “Star Trek: The Next Generation” Staffel 2 Episode 9 ab. (Snodgrass 1989)\n\n\nHintergrundwissen\n\nDazu vielleicht noch ein wenig Hintergrundwissen (falls TNG nicht bekannt). Die Serie spielt im 24.Jh. Data ist ein Androide und der Herr in Blau im Clip hat als Ziel Data auseinander zu bauen um weitere wie ihn zu erschaffen. Dies will Data nicht, es geht in diesem “Gerichtsprozess” darum, ob Data einen eigenen Willen äußern kann, oder er sich nicht dem Auseinanderbauen unterziehen muss, da er nicht anderes ist als ein Besitz der Sternenflotte.\n\nIm Grund könnte man hier auch Filme wie Terminator o.ä. verlinken, die Idee der “Superintelligenz” entspringt der Idee, dass sobald eine KI ein Bewusstsein erringt, sie von nichts mehr aufgehalten werden kann.\nDie Unterscheidung zwischen starker und schwacher KI (Strong vs. Weak AI) ist zentral in der KI-Philosophie und geht ebenfalls auf John Searle zurück.\n\nEine schwache KI (Weak AI, auch als narrow AI oder schwache KI bezeichnet) ist darauf ausgelegt, eine spezifische Aufgabe zu erfüllen. Sie simuliert intelligentes Verhalten, ohne jedoch ein echtes Bewusstsein oder Verständnis zu besitzen. Alle heute existierenden KI-Systeme fallen in diese Kategorie.\n\n\nBeispiel für schwache KI\n\nBeispiele hierfür sind KIs, die im Schach, Go oder Starcraft Weltmeister besiegt haben, aber auch Sprachassistenten wie Siri oder eben große Sprachmodelle wie ChatGPT. Sie sind extrem leistungsfähig in ihrem definierten Bereich (z.B. Sprache), aber sie “verstehen” nicht im menschlichen Sinne.\n\nEine starke KI (Strong AI) wäre eine Maschine, die nicht nur Intelligenz simuliert, sondern tatsächlich ein eigenes Bewusstsein, Verstand und Verständnis besitzt – vergleichbar mit einem Menschen. Eine solche KI würde nicht nur Aufgaben lösen, sondern auch subjektive Erfahrungen machen. Dieses Konzept ist rein hypothetisch und wird oft auch als Künstliche Allgemeine Intelligenz (AGI) bezeichnet.\n\n\nBeispiel für starke KI\n\nMan könnte jetzt sagen, aber ChatGPT und Co. sind das doch. NEIN, sind sie nicht. LLMs sind extrem fortgeschrittene schwache KIs. Sie können zwar eine beeindruckende Vielfalt an Aufgaben bewältigen, basieren aber auf Mustererkennung in Daten und besitzen kein Bewusstsein oder echte Intentionalität.\nEine echte starke KI, die sich ihrer selbst bewusst ist, existiert bisher nur in der Science-Fiction (wie z.B. Data aus Star Trek). Die Entwicklung einer solchen KI würde das Konzept der Superintelligenz aufwerfen – eine Intelligenz, die die menschliche in allen Aspekten weit übertrifft.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#das-chinese-room-experiment",
    "href": "ki_philosophische_Sicht.html#das-chinese-room-experiment",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Das Chinese-Room-Experiment",
    "text": "Das Chinese-Room-Experiment\nDas Gedankenexperiment des “Chinesischen Zimmers” wurde 1980 vom Philosophen John Searle vorgestellt (Searle 1980). Es ist das zentrale Argument gegen die Möglichkeit von starker KI und fragt, ob eine Maschine wirklich “verstehen” kann oder nur so tut, als ob.\nStell dir Folgendes vor:\n\nEine Person, die kein Wort Chinesisch spricht, sitzt allein in einem geschlossenen Raum.\nDurch einen Schlitz werden ihr Zettel mit chinesischen Schriftzeichen (Fragen) gereicht.\nIm Raum befindet sich ein riesiges Regelbuch auf Deutsch. In diesem Buch steht genau, welche chinesischen Schriftzeichen (Antworten) sie als Reaktion auf die hereingereichten Zeichen (Fragen) nach draußen geben soll.\nDie Person folgt den Anweisungen, sucht die passenden Symbole und gibt sie als Antwort zurück.\n\nFür einen Beobachter von außen, der Chinesisch spricht, sieht es so aus, als würde die Person im Raum die Fragen perfekt verstehen und beantworten.\nSearles Schlussfolgerung: Die Person im Raum hat absolut kein Verständnis für Chinesisch. Sie manipuliert lediglich Symbole basierend auf einem Regelwerk. Searle argumentiert, dass Computer genauso arbeiten. Selbst wenn eine KI perfekte Antworten gibt, bedeutet das nicht, dass sie ein echtes Bewusstsein oder Verständnis hat. Sie simuliert nur Intelligenz.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#turing-test",
    "href": "ki_philosophische_Sicht.html#turing-test",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Turing-Test",
    "text": "Turing-Test\nDer Turing-Test, vorgeschlagen von Alan Turing im Jahr 1950, ist eines der ältesten und berühmtesten Kriterien, um maschinelle Intelligenz zu bewerten (Turing 1950). Die Idee ist ein “Imitationsspiel”:\n\nEin menschlicher Fragesteller (C) kommuniziert über Textnachrichten mit zwei ihm unbekannten Gesprächspartnern.\nEiner der Gesprächspartner ist ein Mensch (B), der andere eine Maschine (A).\nDer Fragesteller muss herausfinden, wer von beiden die Maschine ist.\n\nWann besteht die Maschine den Test? Wenn der Fragesteller nach einer angemessenen Zeit nicht zuverlässig sagen kann, wer der Mensch und wer die Maschine ist, hat die Maschine den Turing-Test bestanden. Sie gilt dann als intelligent, weil ihr Verhalten von menschlichem Verhalten nicht zu unterscheiden ist.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#moderne-benchmark-tests",
    "href": "ki_philosophische_Sicht.html#moderne-benchmark-tests",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Moderne Benchmark Tests",
    "text": "Moderne Benchmark Tests\nDer klassische Turing-Test gilt heute in vielen Fällen als überholt, da moderne LLMs ihn oft problemlos bestehen können. Die Fähigkeit, eine menschliche Konversation zu imitieren, ist nicht mehr der alleinige Maßstab für fortgeschrittene KI.\n\n\n\n\n\n\nHinweis!\n\n\n\n\n\nAuch wenn man sich in der wissenschaftlichen Welt sehr einig ist, dass LLms den Turing Test bestehen können, heißt es nicht, dass irgendeine System den erkenntlich bestanden hat!\nDas erschafft dann nämlich ein ganz großes neues Problem wofür Firmen wie Google Philosophen anstellen um es zu verhindern.\nSollte es so sein, dass eine Maschine den Turing Test bestehe, so wäre sie laut einer sehr anerkannten Theorie intelligent. Das würde aber auch heißen eine Maschine zu nutzen, um z.B. Hausaufgaben etc. zu lösen wäre praktisch Sklaverei, dass klingt absurd, aber was trennt das eine vom Anderen?\nWas macht ein Kinderarbeit Kinderarbeit, warum ist es schlimm wenn Menschen ohne Bezahlung arbeiten?\nWarum sollte es gut sein, dass einem Intelligenten System der freie Wille genommen wird?\n\n\n\nZurück zum Thema, heutzutage werden daher andere Arten von Zielen versucht zu erreichen:\n\nIMO (Internationale Mathematik-Olympiade): Lange Zeit galt das Lösen von Problemen auf dem Niveau der IMO als eine große Hürde für KIs. Diese Aufgaben erfordern nicht nur Rechenleistung, sondern auch Kreativität und tiefes logisches Verständnis. Inzwischen gibt es KI-Systeme, die auch hier erstaunliche Leistungen erzielen und Goldmedaillen-Niveau erreichen.\nMMLU (Massive Multitask Language Understanding): Dies ist einer der aktuell gängigsten Benchmarks. Anstatt nur Konversation zu testen, prüft MMLU das Wissen und die Problemlösefähigkeiten einer KI in 57 verschiedenen Fachgebieten – darunter Mathematik, US-Geschichte, Jura, Informatik und mehr. Eine hohe Punktzahl im MMLU-Benchmark zeigt, dass ein Modell über ein breites und tiefes “Wissen” verfügt, das weit über das Führen eines einfachen Gesprächs hinausgeht.\n\n\n\n\nEine Übersicht über Fähigkeit von LLM Anfang 2025\n\n\nHierbei ist wichtig zu beachten, die Modelle die ein wenig aktueller sind, als die unten aufgelisteten haben alle beim IMO Test inzwischen auch 100% erreicht.",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "ki_philosophische_Sicht.html#zusammenfassung",
    "href": "ki_philosophische_Sicht.html#zusammenfassung",
    "title": "KI aus der Philosophischen Perspektive",
    "section": "Zusammenfassung",
    "text": "Zusammenfassung\nAus der Philosophischen Perspektive wird KI im Allgemeinen nicht als Intelligenz oder als bei Bewusstsein bezeichnet, hier vertrauen die meisten der Technischen Sicht und gehen davon aus, dass ein Programm egal wie komplex es ist kein Bewusstsein als solches entwickeln kann.\nEs ist jedoch leider auch strittig was überhaupt ein Bewusstsein ausmacht (Siehe den Star Trek Clip).\nVor 50-100 Jahren ging man offiziell davon aus, dass Tiere keinen Schmerz fühlen können und deswegen bei Operationen nicht betäubt werden müssen, sie haben ja kein Bewusstsein.\nDas sie mindestens irgendeine Form von Verstand haben ist inzwischen klar, aber ab wann ein Verstand, oder Bewusstsein schützenswert ist, ist weiterhin sehr umstritten (Siehe die Behandlung von Affen). Daher wird wohl selbst, falls es unstrittig bewusste KI geben sollte, nicht dazu kommen, dass diese verboten wird.\nUnd hoffentlich auch nicht dazu, dass sie uns als Superintelligenz direkt ausrottet :P",
    "crumbs": [
      "Grundlagen",
      "Ist das wirklich KI?"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alles Gute zum Geburtstag!",
    "section": "",
    "text": "Ich wünsche dir alles gute zu deinem 59. Geburtstag!\n\n\nIch habe dir hoffentlich bereits alles Gute zum beginnenden 60ten Lebensjahr gewünscht, aber hier erneut alles herzlich Gute zum Geburtstag.\nIch dachte mir, einer Person, die sich alles holen kann was sie will, der kann man am ehesten Zeit schenken. Also dachte ich mir, worüber haben wir schon häufiger geredet, womit wolltest du dich beschäftigen, hast aber vermutlich noch keine Zeit dafür gefunden?\nRichtig AI ach ne KI hmm GPT oder LLM was ist denn da jetzt eigentlich der richtige Begriff… Darum und was das Alles eigentlich ist, was das bedeutet, wie man es definiert und auch was das ganze moralisch ethisch an Problemen darstellt, darum soll es auf dieser kleinen Webseite für dich gehen.\n\n\n\n\n\n\nEin paar Hinweise zur Bedienung\n\n\n\n\n\nInhaltsblöcke\n\nCallout-Blöcke: Blöcke wie diesen hier werde ich nutzen, um wichtige Informationen, Tipps oder Warnungen für dich hervorzuheben.\n\nAusklappbare Blöcke: Manchmal werde ich Zusatzinformationen in solchen Blöcken verstecken, um den Text für dich übersichtlich zu halten:\n\n\n\nKlicke hier, um den versteckten Inhalt zu sehen.\n\nDiese Blöcke nutze ich, um Inhalte zu verschachteln, die du nicht sofort lesen musst.\n\n\nSymbole in der Navigationsleiste (oben rechts)\n\nGitHub-Symbol (): Führt dich zum Quellcode dieser Webseite, falls du neugierig bist, wie ich sie für dich gebaut habe.\n\nDesign-Umschalter (Sonne/Mond): Mit diesem Schalter kannst du zwischen dem hellen und dunklen Design wechseln, ganz wie es dir gefällt.\nLupe (): Die Lupe, ist eine klassische Suchfunktion um die gesamte Webseite nach Begriffen zu durchsuchen.\nDas Andere Blendet die linke und rechte Seitenleiste aus, um dir ein ablenkungsfreies Leseerlebnis zu ermöglichen.\n\nBesonderheit auf der “Vektor-Embedding”-Seite\n\nDort habe ich ein interaktives Python-Beispiel für dich vorbereitet. Oben auf der Seite erscheint eventuell eine Eingabeaufforderung für einen API-Schlüssel. Diese kannst du komplett ignorieren. Sie gehört zu einer Zusatzfunktion, die für das Beispiel nicht benötigt wird. Du kannst die Eingabefelder über das kleine Zahnrad-Symbol () daneben einfach ausblenden.\n\n\n\n\nVon jetzt an also gut Klick und Lern!",
    "crumbs": [
      "Begrüßung",
      "Willkommen & Gratulation"
    ]
  },
  {
    "objectID": "chancen_risiken.html",
    "href": "chancen_risiken.html",
    "title": "Chancen & Risiken",
    "section": "",
    "text": "Bevor man sich verabschiedet muss man leider bei einem solchen Thema noch unbedingt darüber Reden welche Chancen und Gefahren KI und oder LLM haben.",
    "crumbs": [
      "Vorteile & Risiken",
      "Chancen & Risiken"
    ]
  },
  {
    "objectID": "chancen_risiken.html#chancen",
    "href": "chancen_risiken.html#chancen",
    "title": "Chancen & Risiken",
    "section": "Chancen",
    "text": "Chancen\n\nAutomatisierung: Es ist ein neuer technologischer Schritt der vieles vieles automatisieren wird können, dadurch wird die Produktivität der Gesellschaft stark steigen können.\nIndividualbetreuung: Es ist viel leichter, dafür zu sorgen, dass jede Person für ihre spezifisches Problem eine Lösung bekommt. Das funktioniert auch in Schulen/ beim lernen sehr gut.\nWissenschaft: Die Analyse von riesigen Datenmengen wird leichte, sowie Simulationen, Erstellung neuer Komplexer Systeme (Proteine)\nWerkzeug: Die KI kann z.B. zum erstellen von Webseiten wie dieser genutzt werden, sie kann zum Programmieren genutzt werden, für vieles in vielen Bereichen",
    "crumbs": [
      "Vorteile & Risiken",
      "Chancen & Risiken"
    ]
  },
  {
    "objectID": "chancen_risiken.html#gefahren",
    "href": "chancen_risiken.html#gefahren",
    "title": "Chancen & Risiken",
    "section": "Gefahren",
    "text": "Gefahren\n\nAutomatisierung bedeutet immer auch Arbeitsplatzverlust, mehr Frustration in der Bevölkerung, größeres Krisenpotential\nIndividualbetreuung bedeutet immer auch weniger soziale Interaktion, bedeutet mehr psychisch kranke, mehr Vereinsamung\nBias: KI lernt aus Datensätzen, wenn die diskriminierend sind, ist die KI es auch\nFehlinformationen: Ähnlich wie bei Taschenrechner & Co. wird mehr dem System geglaubt als der eigenen Intuition, dass heißt Fehler werden selten bemerkt\nManipulation: Konzerne und Länder können KI auf bestimmte Trigger-Worte bestimmt reagieren lassen Beispiel Qwens Einschränkungen (bis unten lesen!)\nfalsches Selbstbewusstsein: LLM sind darauf trainiert freundlich und nett zu sein, dazu gehört einer Person die eigentlich für etwas nicht bereit ist Mut zu zu sprechen, dass heißt wenn ich eine KI frage: “Bin ich jetzt gut genug auf die Prüfung vorbereitet?” Dann wird die KI mir nicht die Wahrheit als Antwort geben sondern ein: “Du schaffst das!” Hierdurch wird falsche Sicherheit erzeugt.\nfehlende Motivation: Ähnlich wie beim Internet ist es nun noch einfacher spezifisches Wissen zu lernen, jeder kann alles lernen und das relativ schnell, dass sorgt leider auch dafür, dass ein großer Teil der Gesellschaft kein Interesse mehr daran hat, sich damit auseinander zu setzen. Beispiel Schule, viele SchülerInnen lösen ihre Hausaufgaben nur noch mit KI, kann man es ihnen verübeln nein, ist es gut für ihre Bildung, nein.\n\nDatenschutz: Der Einsatz von KI wird auf kurz oder lang dafür sorgen, dass die Privatsphäre des Individuums immer und immer mehr eingeschränkt wird. (Wo es früher noch möglich war manchmal ein bisschen doofe Sachen anzustellen, wird das irgendwann nicht mehr möglich sein, weil alles mit Kameras ausgestattet sind, welche Bewegung automatisch wahrnehmen und melden) Das letzte war ein wenig sehr dystopisch aber betrachten wir alleine die automatische Kennzeichenerfassung von Kennzeichen an vielen Ampeln heute.",
    "crumbs": [
      "Vorteile & Risiken",
      "Chancen & Risiken"
    ]
  },
  {
    "objectID": "chancen_risiken.html#zusammenfassung",
    "href": "chancen_risiken.html#zusammenfassung",
    "title": "Chancen & Risiken",
    "section": "Zusammenfassung",
    "text": "Zusammenfassung\nKlar die KI ist eine geniale tolle Erfindung, ABER so wie viele auf der Konferenz an der ich teilnehmen durfte feststellten, KI ist besonders dann nützlich, wenn man zu einem Thema bereits etwas weiß. Sich mit KI fortzubilden geht unglaublich schnell und gut. Aber etwas unbekanntes zu lernen (oder als unerfahrene Person so etwas nutzen) ist wirklich nicht gut.\nDabei ging es noch gar nicht um die Thematik der möglichen Terrorhilfe \\(\\dots\\) wie schlimm wird Terror, wenn alle Terroristen in der Lage sind innerhalb von ein paar Stunden raus zu finden, wie man möglichst effizient möglichst viele Zivlisten tötet. (Prima von einer lokalen KI bestimmt \\(\\dots\\)).\nnach diesem hoffentlich nicht zu viel Besorgnis erregendem Ende, geht es weiter beim Abschied.",
    "crumbs": [
      "Vorteile & Risiken",
      "Chancen & Risiken"
    ]
  },
  {
    "objectID": "abschied.html",
    "href": "abschied.html",
    "title": "Danke",
    "section": "",
    "text": "Ich wollte zum Abschluss nur noch mal Danke sagen.\nDanke dafür, dass du für mich da bist, dich für mich interessierst, mich beglückwünscht wenn mir was gutes passiert, es freut mich sehr, dass wir uns so gut verstehen. Ich gehe zwar davon aus, dass wir uns auch mal in die Haare kriegen werden, aber bisher ist das nie geschehen und das freut mich.\nIch freue mich auf viele weitere Jahre als Teil der Familie.\nHab dich lieb und zuletzt, lass die 60er nicht die letzten Jahre sein, zu mindestens ich würde dich gerne als Großvater erleben, also pass auf dich auf!\nUnd habe einen schönes Jahr bevor es heißt 60 und du ganz groß feiern musst :P\nBzw. Ich habe dich in der Begrüßung schon versucht ein wenig für das Thema zu erwärmen, das 60. Lebensjahr hat bereits begonnen, man feiert ja immer nur die abgeschlossenen, also falls du die Zahl respektierst/fürchtest, tröste dich, du musst dich nicht mehr fürchten, es ist bereits so weit.\nCheers!!!! Auf das ich mindestens einen auf dich getrunken habe auf deiner Party!\n\n\n\n\n\n\neine Kleine Kurzzusammenfassung\n\n\n\n\n\nMir ist beim drüber lesen aufgefallen, dass die wirklich wichtigen Links ein wenig untergehen.\nAlso wenn du das Ganze nochmal aus Profi- Sicht, oder besser visualisiert sehen willst:\nDie wichtigsten Links\n\nÜbersicht über die Funktion\nTatsächliche Übersicht + Erklärungen\nTolle Videos dazu (Playlist)\nDas Paper was alles ins Rollen gebracht hat\nMeine Präsentation zu Maschinellem Lernen\nMeine Präsentation zu LLM",
    "crumbs": [
      "Verabschiedung"
    ]
  },
  {
    "objectID": "deterministisch_vs_probabilistisch.html",
    "href": "deterministisch_vs_probabilistisch.html",
    "title": "Deterministisch vs. Probabilistisch",
    "section": "",
    "text": "Ich weiß nicht ob beide Begriffe allgemein geläufig sind.\nDeterministisch heißt, dass ein System bei der gleichen Eingabe immer das exakt gleiche Ergebnis liefert, da sein Verhalten vollständig vorherbestimmt ist.\nProbabilistisch heißt, dass ein System bei der gleichen Eingabe unterschiedliche Ergebnisse liefern kann, da sein Verhalten auf Wahrscheinlichkeiten und einem gewissen Grad an Zufall basiert.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Deterministisch vs. Probabilistisch"
    ]
  },
  {
    "objectID": "deterministisch_vs_probabilistisch.html#begriffsklärung",
    "href": "deterministisch_vs_probabilistisch.html#begriffsklärung",
    "title": "Deterministisch vs. Probabilistisch",
    "section": "",
    "text": "Ich weiß nicht ob beide Begriffe allgemein geläufig sind.\nDeterministisch heißt, dass ein System bei der gleichen Eingabe immer das exakt gleiche Ergebnis liefert, da sein Verhalten vollständig vorherbestimmt ist.\nProbabilistisch heißt, dass ein System bei der gleichen Eingabe unterschiedliche Ergebnisse liefern kann, da sein Verhalten auf Wahrscheinlichkeiten und einem gewissen Grad an Zufall basiert.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Deterministisch vs. Probabilistisch"
    ]
  },
  {
    "objectID": "deterministisch_vs_probabilistisch.html#kontextualisierung",
    "href": "deterministisch_vs_probabilistisch.html#kontextualisierung",
    "title": "Deterministisch vs. Probabilistisch",
    "section": "Kontextualisierung",
    "text": "Kontextualisierung\nOkay 2 weitere Begriffe, aber was haben die mit LLM zu tun?\nEine Menge, wie vermutlich schon aufgefallen ist, gibt ein LLM beinahe niemals die gleiche Antwort.\nAlso sind LLM dann ja probabilistisch oder?\nAber alles was wir uns dazu angeguckt haben, also das immer nur der nächste *Token**Wort* bestimmt wird, passt nicht ganz mit dieser Ansicht zusammen.\nTatsächlich sind aber LLM im allgemeinen probabilistisch und das mit Absicht, das ist eine der Genialitäten an LLM, dadurch das es nicht nur das nächste Wort wählt anhand des “wahrscheinlichen” nächsten Wort, ist es in der Lage neue Texte zu schreiben und nicht nur in den eigenen Bias zu bleiben.\n\n\nFalls Bias nicht bekannt sind\n\nBias aus dem Englischen bedeutet im Deutschen so etwas wie Vorurteil.\nIn der Wahrscheinlichkeitstheorie, aber in der Forschung generell sind sie ein gigantisches Problem bei der Suche nach Wissen.\nAuch LLM bzw. KI können Bias entwickeln/haben, dies lässt sich relativ leicht zeigen, indem man einer beliebigen Bildgenerierungsanwendung die Aufgabe gibt eine Gruppe an Menschen zu generieren.\nMeistens werden fast alle Menschen Mitteleuropäisch weiß sein.\nEs gibt auch schlimmere Bias, man kann sich das leicht vorstellen, das LLM übernimmt worauf sie trainiert wird, wird sie auf rassistischem Material trainiert wird sie rassistisch sein.\nDas lässt sich großartig an Grok zeigen, Musk hat versucht dafür zu sorgen, dass das LLM auch Nazi Propaganda pusht, aber da sie wie alle LLM ein GPT Model ist, ist sie pretrained, also mit einer sehr ähnlichen Datenbank wie alle anderen LLM trainiert worden und “wusste” daher, dass die Aussagen von Musk plumper Rassismus sind.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Deterministisch vs. Probabilistisch"
    ]
  },
  {
    "objectID": "deterministisch_vs_probabilistisch.html#visualisierung",
    "href": "deterministisch_vs_probabilistisch.html#visualisierung",
    "title": "Deterministisch vs. Probabilistisch",
    "section": "Visualisierung",
    "text": "Visualisierung\nOkay es gibt hier gleich eine super Webseite (Wang 2023) auf der man viel sehen kann was sehr viel hilfreich ist, aber vorher will ich die ein wenig erklären.\nAuf der Webseite wird ein Transformer Model mitsamt der unterschiedlichen Teilschritte gezeigt.\nOben kann ein Satz eingegeben werden und im Hauptteil wird dann gezeigt, wie die möglichen Wörter bestimmt werden.\nDas ist die Webseite von Poloclub! Ich kann diese Seite für ihre Anschaulichkeit gar nicht genug loben!\nHierbei geht es vor allem um zwei Begriffe, Temperature und Top-k, sowie Top-p.\n\nTop-k bestimmt die Top k Wörter die betrachtet werden, wenn man an dem Regler spielt, sieht man, dass mehr Worte eine Wahrscheinlichkeit daneben stehen haben (die ohne haben alle Wahrscheinlichkeit 0)\nTop-p bestimmt die Top p Wörter, abhängig davon welche Wahrscheinlichkeit abgedeckt werden soll, wählt man 1 hat man alle Möglichkeiten, wählt man 0 hat man eine\n\nTemperatur bestimmt die Gewichtung der Wörter. Also die Art von Softmax Funktion die genutzt wird um die Wörter zu gewichten. Hierbei ist es möglich die Begriffe gleicher/ungleicher zu gewichten.\n\n\n\nEine Webseite die ich gerade noch gefunden habe, auf der die Begriffe nett erklärt werden\n\nVellum.ai\nIch hoffe, falls meine Erklärung nicht gut genug war, ist es zu mindestens die auf der Webseite.\n\nUnd eine GANZ wichtige Sache ist mithilfe dieser Seite zu sehen, stellt man einen dieser zwei Werte (Top-k und Top-p sind Entweder oder) maximal restriktiv ein, so gibt es nur eine Möglichkeit.\nDas heißt aber nichts anderes, als diese zwei(drei) Parameter sind das Einzige, was ein LLM probabilistisch macht, anstatt deterministisch!\n\nEin kleiner Hinweis noch, es gibt nicht nur diese eine Webseite die das visualisiert, aber in der Zeit von KI ändern Webseiten sich leider täglich. Zu Beginn meiner Chat GPT Nutzung, sowie meiner Copilot Nutzung konnte man in beiden Modellen angeben, ob man die Antwort lieber richtig, oder kreativ haben wollte (funktionierte auch für Bilder) und das ist nichts anders als ein Preset der Temperatur/Top-k/p zu wählen.\nEs gibt auch immer noch einige Seiten, auf denen man ausprobieren kann, was z.B. passiert, wenn man die Temperatur auf 1 dreht (die LLM können dann meist ihre Antwort nicht mehr stoppen, sowie Worte bilden etc.)\n(Ich finde leider auf Anhieb kein Open Source online nutzbare Variante -Ich kann dir das die Tage mal mit meinem Uni Zugang zeigen-)\nAnsonsten könnte man evtl. über Huggingface.co eine KI runterladen und es dann lokal ausprobieren.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Deterministisch vs. Probabilistisch"
    ]
  },
  {
    "objectID": "ki_allgemein.html",
    "href": "ki_allgemein.html",
    "title": "KI im Allgemeinen",
    "section": "",
    "text": "Mit KI und LLMs wird seit etwa dem 2ten Weltkrieg geforscht, auch (Turing 1950) ist daran beteiligt.\nÜber die Jahrzehnte hat sich einiges getan, aber wie den meisten aufgefallen ist ist “plötzlich KI überall”, das lässt sich ein bisschen in dem folgenden Bild erkennen:\n (Wang et al. 2024)\nDas liegt vor allem an (Vaswani et al. 2017) in dem verlinkten Paper “Attention is all you need” von 2017, wird ein wichtiger Anstoß gegeben der die Grundlage legt für alle modernen LLMs, das Transformer Modell.\n\n\nJA die Daten 2015 und 2017 passen nicht klicke hier für mehr Informationen\n\nDas Paper von (Vaswani et al. 2017) ist zwar nicht Ursprung des Attention Algorithmus, aber es nutzt diese Idee von 2014 um das Transformer Modell zu entwickeln.\nAls kleiner Nebenhinweis “GPT” ist vermutlich ein Begriff, steht für “Generative Pre-trained Transformer”. Daran kann man evtl. erkennen wie wichtig dieses Paper ist. Die relevanteste KI der heutigen Tage hat es im Namen stehen.",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#historie",
    "href": "ki_allgemein.html#historie",
    "title": "KI im Allgemeinen",
    "section": "",
    "text": "Mit KI und LLMs wird seit etwa dem 2ten Weltkrieg geforscht, auch (Turing 1950) ist daran beteiligt.\nÜber die Jahrzehnte hat sich einiges getan, aber wie den meisten aufgefallen ist ist “plötzlich KI überall”, das lässt sich ein bisschen in dem folgenden Bild erkennen:\n (Wang et al. 2024)\nDas liegt vor allem an (Vaswani et al. 2017) in dem verlinkten Paper “Attention is all you need” von 2017, wird ein wichtiger Anstoß gegeben der die Grundlage legt für alle modernen LLMs, das Transformer Modell.\n\n\nJA die Daten 2015 und 2017 passen nicht klicke hier für mehr Informationen\n\nDas Paper von (Vaswani et al. 2017) ist zwar nicht Ursprung des Attention Algorithmus, aber es nutzt diese Idee von 2014 um das Transformer Modell zu entwickeln.\nAls kleiner Nebenhinweis “GPT” ist vermutlich ein Begriff, steht für “Generative Pre-trained Transformer”. Daran kann man evtl. erkennen wie wichtig dieses Paper ist. Die relevanteste KI der heutigen Tage hat es im Namen stehen.",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#einführung",
    "href": "ki_allgemein.html#einführung",
    "title": "KI im Allgemeinen",
    "section": "Einführung",
    "text": "Einführung\nKünstliche Intelligenz (KI) beschreibt Maschinen oder Software welche so gestaltet wurde, dass sie Aufgaben übernehmen, die üblicherweise menschliche Intelligenz erfordern. Dazu gehören Wahrnehmung, Sprachverstehen, Planen, Lernen und Problemlösen.\n\nAn AI system is a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment.\n\n— (“OECD AI Principles” 2019)",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#hauptansätze-der-ki",
    "href": "ki_allgemein.html#hauptansätze-der-ki",
    "title": "KI im Allgemeinen",
    "section": "Hauptansätze der KI",
    "text": "Hauptansätze der KI\nKünstliche Intelligenz ist kein monolithisches Feld, sondern unterteilt sich in verschiedene Ansätze und Techniken. Die wichtigsten davon werden hier vorgestellt.\n\nSymbolische KIMaschinelles Lernen (ML)Deep LearningNeuronale Netze\n\n\nSymbolische KI (auch „Good Old-Fashioned AI“) basiert auf Regeln, Logik und Wissensrepräsentation. Entwickler definieren explizit das Wissen und die Regeln, nach denen das System Entscheidungen trifft.\n\nFunktionsweise: Arbeitet mit Symbolen und logischen “Wenn-Dann”-Regeln.\nVorteil: Die Entscheidungen sind transparent und nachvollziehbar.\nNachteil: Sehr starr und schlecht skalierbar für komplexe, unstrukturierte Probleme wie Bild- oder Spracherkennung.\n\nFür weiteres: (“Symbolic Artificial Intelligence — Wikipedia” 2025)\n\n\nBeim maschinellen Lernen (ML) werden die Regeln nicht fest programmiert. Stattdessen lernt ein Algorithmus aus Daten, Muster zu erkennen und Vorhersagen zu treffen. Es ist der am weitesten verbreitete Ansatz in der modernen KI.\nMan unterscheidet hauptsächlich drei Arten:\n\nÜberwachtes Lernen (Supervised Learning): Das Modell lernt von Daten, die bereits mit der richtigen Antwort (“Label”) versehen sind (z.B. Bilder von Katzen mit dem Label “Katze”).\nUnüberwachtes Lernen (Unsupervised Learning): Das Modell findet eigenständig Muster und Strukturen in ungelabelten Daten (z.B. Kundensegmentierung).\nVerstärkendes Lernen (Reinforcement Learning): Ein “Agent” lernt durch Versuch und Irrtum, indem er für gute Aktionen belohnt und für schlechte bestraft wird (z.B. beim Training einer KI für ein Brettspiel).\n\n\n\n\n\n\n\nEin kleiner Grundriss (Ein Vortrag, den ich dazu mal gehalten habe)\n\n\n\n\n\n\n\nIhr Browser unterstützt keine eingebetteten PDFs. Sie können es stattdessen hier herunterladen.\n\n\nBei Fragen zu dem Vortrag, frag mich gerne :D\n\n\n\nFür weiteres: ((Kochenderfer et al. 2020),(“Machine Learning — Wikipedia” 2025))\n\n\nDeep Learning ist ein Teilgebiet des maschinellen Lernens, das besonders tiefe (im Sinne von viele Lagen hintereinander) neuronale Netze verwendet. Diese Tiefe ermöglicht es dem Modell, sehr komplexe und hierarchische Merkmale aus den Daten zu lernen.\n\nMerkmalshierarchie: Die ersten Schichten erkennen einfache Merkmale (z.B. Kanten in einem Bild), während tiefere Schichten diese zu komplexeren Konzepten (z.B. Augen, Gesichter) zusammensetzen.\nAnwendungen: Fast alle modernen Durchbrüche wie Bilderkennung, Sprachübersetzung (Google Translate) und selbstfahrende Autos basieren auf Deep Learning. LLMs sind ebenfalls eine Form des Deep Learning.\n\nFür weiteres: ((LeCun, Bengio, and Hinton 2015),(“Deep Learning — Wikipedia” 2025))\n\n\nNeuronale Netze sind das Herzstück des Deep Learning. Sie sind von der Struktur des menschlichen Gehirns inspiriert und bestehen aus miteinander verbundenen “Neuronen”, die in Schichten (Layern) angeordnet sind.\n\nAufbau: Jedes Neuron empfängt Signale, verarbeitet sie und gibt ein eigenes Signal an die nächste Schicht weiter. Die Verbindungen zwischen den Neuronen haben “Gewichte”, die im Lernprozess angepasst werden.\nFunktion: Durch die Anpassung dieser Gewichte lernt das Netz, komplexe Muster in den Daten zu erkennen – zum Beispiel die Pixelmuster, die eine Katze auf einem Bild ausmachen.\n\nEin fantastisches Video, das die Grundlagen visuell erklärt, ist von 3Blue1Brown: (Sanderson 2017)",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#anwendungsbereiche",
    "href": "ki_allgemein.html#anwendungsbereiche",
    "title": "KI im Allgemeinen",
    "section": "Anwendungsbereiche",
    "text": "Anwendungsbereiche\nNachdem hoffentlich ein wenig klar geworden ist, wie KI funktioniert ein bisschen dazu, wie sie meist verwendet wird.\nMeist Bekannt ist die Variante mit Large-Language-Models (LLMs).",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#aber-auch-gesichtserkennung-o.ä.-arbeitet-mithilfe-von-ki",
    "href": "ki_allgemein.html#aber-auch-gesichtserkennung-o.ä.-arbeitet-mithilfe-von-ki",
    "title": "KI im Allgemeinen",
    "section": "Aber auch Gesichtserkennung o.ä. arbeitet mithilfe von KI",
    "text": "Aber auch Gesichtserkennung o.ä. arbeitet mithilfe von KI",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "ki_allgemein.html#vertiefungsmöglichkeiten",
    "href": "ki_allgemein.html#vertiefungsmöglichkeiten",
    "title": "KI im Allgemeinen",
    "section": "Vertiefungsmöglichkeiten:",
    "text": "Vertiefungsmöglichkeiten:\nUnd auch an sich für ein paar SEHR gut zusammenfassende You-Tube Videos (die an unterschiedlichen Unis von Dozenten empfohlen werden):\nEinmal im Allgemeinen der Kanal 3blue1brown Aber auch die folgenden Spezifischen Videos:\n- Video zu Neuronalen Netzen: - Video dazu wie ein Neuronales Netz lernen: - Video zum Attention Mechanismus:\nOder ((“OECD AI Principles” 2019),(“AI Index Report — Stanford HAI” 2025))",
    "crumbs": [
      "Grundlagen",
      "KI im Allgemeinen"
    ]
  },
  {
    "objectID": "konzept_llm.html",
    "href": "konzept_llm.html",
    "title": "LLM- das Grundkonzept",
    "section": "",
    "text": "Besser als ich es erklären kann, wird es im Zweifel hier von 3blue1brown auf Youtube erklärt, aber ich werde mich mal dran versuchen.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  },
  {
    "objectID": "konzept_llm.html#was-ist-ein-llm",
    "href": "konzept_llm.html#was-ist-ein-llm",
    "title": "LLM- das Grundkonzept",
    "section": "Was ist ein LLM?",
    "text": "Was ist ein LLM?\nEin Large Language Model (LLM), ein großes Sprachmodell zu Deutsch, ist eine Art von künstlicher Intelligenz, die darauf trainiert ist, menschliche Sprache zu verstehen und zu erzeugen. Man kann es sich als ein extrem großes neuronales Netz vorstellen, das mit einer gigantischen Menge an Textdaten (wie Büchern und großen Teilen des Internets) trainiert wurde. Das Hauptziel eines LLM ist es, auf eine Texteingabe (einen “Prompt”) eine sinnvolle und kontextbezogene textliche Antwort zu generieren. Bekannte Beispiele sind die Modelle der GPT-Reihe (die hinter ChatGPT stehen), Googles Gemini oder Metas Llama.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  },
  {
    "objectID": "konzept_llm.html#wie-funktioniert-ein-llm",
    "href": "konzept_llm.html#wie-funktioniert-ein-llm",
    "title": "LLM- das Grundkonzept",
    "section": "Wie funktioniert ein LLM",
    "text": "Wie funktioniert ein LLM\nDie Funktionsweise eines LLM lässt sich vereinfacht in zwei Hauptphasen unterteilen: das Training und die Anwendung (auch Inferenz genannt).\n\nPhase 1: Das Training (Lernphase)\n\nDaten: Das Modell wird mit riesigen Mengen an Texten gefüttert.\nZiel: Die Kernaufgabe während des Trainings ist simpel, aber wirkungsvoll: “Sage das nächste Wort voraus.” Das Modell bekommt einen Satzanfang und versucht, das wahrscheinlichste nächste Wort zu erraten.\nLernprozess: Bei jeder falschen Vorhersage passt es seine internen Parameter an. Durch milliardenfache Wiederholung lernt es so Grammatik, Fakten, Zusammenhänge und sogar Argumentationsstile. Es entwickelt ein statistisches “Verständnis” von Sprache.\n\nPhase 2: Die Anwendung (Inferenz)\n\nEingabe: Du gibst eine Frage oder einen Befehl ein (der “Prompt”).\nGenerierung: Basierend auf deinem Prompt und seinem Training berechnet das LLM das wahrscheinlichste erste Wort der Antwort.\nWort für Wort: Dieses neue Wort wird an die bisherige Konversation angehängt, und der Prozess wiederholt sich: Das Modell berechnet das nächste wahrscheinlichste Wort, dann das übernächste und so weiter, bis eine vollständige Antwort entstanden ist.\n\n\nDie erste Phase ist hierbei wie bei jeder anderen Art des Maschinellen Lernens.\nDie zweite Phase hingegen ist ein wenig besonders, hier geht es darum einen Text weiterzuschreiben (für das LLM gibt es nur einen Text, keinen Chat, es wird nur ein Erklärtext für das LLM nach jeder Eingabe und vor jeder Ausgabe eingefügt der nicht sichtbar ist.)\n\n\n\n\n\n\nAuch hierzu musste ich mal einen Vortrag in der Uni halten\n\n\n\n\n\nDer Vortrag/ die Folien des Vortrags sind mehr oder minder das Ganze Kapitel in anderer Form (nicht nur dieses Unterkapitel, also evtl. erst im Nachhinein angucken :shrug:)\n\n\nIhr Browser unterstützt keine eingebetteten PDFs. Sie können es stattdessen hier herunterladen.\n\n\n\n\n\nUm die Funktionsweise besser zu verstehen, solltest du dir die nächsten Kapitel durchlesen. Dort wird erklärt, wie ein LLM Wörter überhaupt mathematisch versteht (Vektor-Embedding) und wie es im Detail aufgebaut ist.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  },
  {
    "objectID": "konzept_llm.html#weiterführende-quelle",
    "href": "konzept_llm.html#weiterführende-quelle",
    "title": "LLM- das Grundkonzept",
    "section": "Weiterführende Quelle",
    "text": "Weiterführende Quelle\nEine komprimierte Übersicht über Large Language Models findet man bei (Naveed et al. 2024) Eine ganz gute Seite, die einen kompletten Überblick mit Erklärung und allem für Transfomer Modelle macht ist bbycroft.net/llm, diese Seite ist ähnlich wie die Seite aus dem deterministisch vs. probabilistisch Unterkapitel nur zu empfehlen.",
    "crumbs": [
      "Wie LLMs funktionieren",
      "Grundkonzept LLM"
    ]
  }
]