---
title: Deterministisch vs. Probabilistisch
bibliography: literatur.bib
---

## Begriffsklärung

Ich weiß nicht, ob beide Begriffe allgemein geläufig sind.
**Deterministisch** heißt, dass ein System bei der gleichen Eingabe immer das exakt gleiche Ergebnis liefert, da sein Verhalten *vollständig vorherbestimmt* ist.

**Probabilistisch** heißt, dass ein System bei der gleichen Eingabe unterschiedliche Ergebnisse liefern kann, da sein Verhalten auf Wahrscheinlichkeiten und einem *gewissen Grad an Zufall* basiert.

## Kontextualisierung
Okay, zwei weitere Begriffe, aber was haben diese mit LLMs zu tun?
Eine Menge! Wie dir vermutlich schon aufgefallen ist, gibt ein LLM beinahe niemals die gleiche Antwort.
Also sind LLMs dann ja probabilistisch, oder?
Aber alles, was wir uns dazu angeguckt haben – also dass immer nur das nächste *Token* (Wort) bestimmt wird – passt nicht ganz zu dieser Ansicht.

Tatsächlich sind LLMs im Allgemeinen probabilistisch, und das mit Absicht. Das ist eine der Genialitäten an ihnen: Dadurch, dass ein LLM nicht stur das wahrscheinlichste nächste Wort wählt, ist es in der Lage, kreative und neue Texte zu schreiben, anstatt nur im eigenen "Bias" zu verharren.

<details>
<summary> Falls Bias nicht bekannt sind </summary>
Bias (aus dem Englischen) bedeutet im Deutschen so etwas wie Voreingenommenheit oder Vorurteil.
In der Wahrscheinlichkeitstheorie, aber auch in der Forschung generell, sind sie ein großes Problem bei der Suche nach objektivem Wissen.
Auch LLMs bzw. KI können einen Bias entwickeln oder aufweisen. Dies lässt sich relativ leicht zeigen, indem man einer beliebigen Bild-KI die Aufgabe gibt, eine "Gruppe von Menschen" zu generieren.
Meistens werden fast alle dargestellten Menschen mitteleuropäisch und weiß sein.
Es gibt auch schlimmere Bias. Man kann sich das leicht vorstellen: Das LLM übernimmt, womit es trainiert wird. Wird es mit rassistischem Material trainiert, wird es rassistisch sein.
Ein bekanntes Beispiel ist "Grok". Berichten zufolge hat Elon Musk versucht, das LLM so auszurichten, dass es bestimmte politische Ansichten fördert. Da es aber – wie alle großen Modelle – auf einem riesigen, allgemeinen Datensatz vortrainiert wurde, hat das Modell oft "gelernt", dass solche extremen Aussagen nicht der Norm entsprechen.
</details>

## Visualisierung
Okay, es gibt hier gleich eine super Webseite [@poloclubTransformerExplainer], auf der man viel sehen kann, was sehr hilfreich ist. Aber vorher will ich sie ein wenig erklären.
Auf der Webseite wird ein Transformer-Modell mitsamt der unterschiedlichen Teilschritte gezeigt.
Oben kann ein Satz eingegeben werden, und im Hauptteil wird dann visualisiert, wie die möglichen nächsten Wörter bestimmt werden.

[Das ist die Webseite von Poloclub!](https://poloclub.github.io/transformer-explainer/)
*Ich kann diese Seite für ihre Anschaulichkeit gar nicht genug loben!* 

Hierbei geht es vor allem um drei Parameter: **Temperature**, **Top-k** und **Top-p**.

- **Top-k** bestimmt die Anzahl der wahrscheinlichsten Wörter, die für die nächste Auswahl überhaupt in Betracht gezogen werden. Wenn man an dem Regler spielt, sieht man, dass mehr Wörter eine Wahrscheinlichkeit zugewiesen bekommen (die anderen haben die Wahrscheinlichkeit 0).
- **Top-p** funktioniert ähnlich, wählt aber nicht eine feste Anzahl, sondern so viele Wörter, bis deren summierte Wahrscheinlichkeit einen bestimmten Schwellenwert (p) erreicht.
- **Temperatur** bestimmt die Gewichtung der Wörter,dadurch wird "Kreativität" bzw. Zufälligkeit der Auswahl verändert. Eine hohe Temperatur macht die Wahrscheinlichkeiten der möglichen Wörter ähnlicher, was zu überraschenderen Ergebnissen führt. Eine niedrige Temperatur verstärkt die wahrscheinlichsten Optionen und macht die Antwort vorhersagbarer.

<details>
<summary> Eine Webseite die ich gerade noch gefunden habe, auf der die Begriffe nett erklärt werden </summary>

[Vellum.ai](https://www.vellum.ai/llm-parameters/temperature?utm_source=duckduckgo&utm_medium=organic)

Ich hoffe, falls meine Erklärung nicht gut genug war, ist es zumindest die auf der Webseite.

Und eine GANZ wichtige Sache ist mithilfe dieser Seite zu sehen, stellt man einen dieser zwei Werte (Top-k und Top-p sind Entweder oder) maximal restriktiv ein, so gibt es nur **eine** Möglichkeit.  
Das heißt aber nichts anderes, als diese zwei(drei) Parameter sind **das Einzige**, was ein LLM probabilistisch macht, anstatt deterministisch!  

---
Ein kleiner Hinweis noch: Es gibt nicht nur diese eine Webseite, die das visualisiert, aber in der schnelllebigen Zeit der KI ändern sich Webseiten leider täglich. Zu Beginn meiner ChatGPT- und Copilot-Nutzung konnte man in beiden Modellen angeben, ob man die Antwort lieber "präzise" oder "kreativ" haben wollte. Das ist nichts anderes als ein voreingestellter Wert für Temperatur, Top-k oder Top-p.

Es gibt auch immer noch einige Seiten, auf denen man ausprobieren kann, was z.B. passiert, wenn man die Temperatur auf 1 dreht (die LLM können dann meist ihre Antwort nicht mehr stoppen, sowie Worte bilden etc.)  
(Ich finde leider auf Anhieb kein Open Source online nutzbare Variante -Ich kann dir das die Tage mal mit meinem Uni Zugang zeigen-)  
Ansonsten könnte man evtl. über [Huggingface.co](https://huggingface.co/) eine KI herunterladen und es dann lokal ausprobieren.
</details>
