---
title: "KI im Allgemeinen"
bibliography: literatur.bib
---
## Historie

Mit KI und LLMs wird seit etwa dem Zweiten Weltkrieg geforscht, auch [@turing1950computing] ist daran beteiligt.
Über die Jahrzehnte hat sich einiges getan, aber wie den meisten aufgefallen ist, ist "plötzlich KI überall". Das lässt sich gut in dem folgenden Bild erkennen:

![Zeitleiste der KI-Entwicklung](Quellen/Historie.png){width="100%"}
[@wang2024historydevelopmentprincipleslarge]

Wie im Bild auch zu sehen ist, geht ab der Erfindung des **Transformer-Modells** alles sehr schnell. Das relevante Paper wurde von [@vaswani2017attention] veröffentlicht.

<details>
<summary>Warum passen die Jahreszahlen 2015 und 2017 nicht zusammen? Klicke hier!</summary>
Das Paper von [@vaswani2017attention] ist zwar nicht der Ursprung des Attention-Algorithmus, aber es nutzt diese Idee von 2014, um das Transformer-Modell zu entwickeln.
Als kleiner Nebenhinweis "GPT" ist vermutlich ein Begriff, steht für "Generative Pre-trained Transformer".  
Daran kann man erkennen, wie wichtig dieses Paper ist:   Die relevanteste KI unserer Zeit trägt es im Namen.
</details>

## Einführung

Künstliche Intelligenz (KI) beschreibt Maschinen oder Software, die so gestaltet wurde, dass sie Aufgaben übernimmt, die üblicherweise menschliche Intelligenz erfordern. Dazu gehören Wahrnehmung, Sprachverstehen, Planen, Lernen und Problemlösen.

> An AI system is a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment.
>
> <p style="text-align: right;">— [@oecd_ai]</p>

## Hauptansätze der KI

Künstliche Intelligenz ist kein monolithisches Feld, sondern unterteilt sich in verschiedene Ansätze und Techniken. Die wichtigsten davon werden hier vorgestellt.

::: panel-tabset
### Symbolische KI

Symbolische KI (auch „Good Old-Fashioned AI“) basiert auf Regeln, Logik und Wissensrepräsentation. Entwickler definieren explizit das Wissen und die Regeln, nach denen das System Entscheidungen trifft.

-   **Funktionsweise:** Arbeitet mit Symbolen und logischen "Wenn-Dann"-Regeln.
-   **Vorteil:** Die Entscheidungen sind transparent und nachvollziehbar.
-   **Nachteil:** Sehr starr und schlecht skalierbar für komplexe, unstrukturierte Probleme wie Bild- oder Spracherkennung.

Für weiteres: [@wiki_symbolicAI]

### Maschinelles Lernen (ML)

Beim maschinellen Lernen (ML) werden die Regeln nicht fest programmiert. Stattdessen lernt ein Algorithmus aus Daten, Muster zu erkennen und Vorhersagen zu treffen. Es ist der am weitesten verbreitete Ansatz in der modernen KI.

Man unterscheidet hauptsächlich drei Arten:

-   **Überwachtes Lernen (Supervised Learning):** Das Modell lernt von Daten, die bereits mit der richtigen Antwort ("Label") versehen sind (z.B. Bilder von Katzen mit dem Label "Katze").
-   **Unüberwachtes Lernen (Unsupervised Learning):** Das Modell findet eigenständig Muster und Strukturen in ungelabelten Daten (z.B. Kundensegmentierung).
-   **Verstärkendes Lernen (Reinforcement Learning):** Ein "Agent" lernt durch Versuch und Irrtum, indem er für gute Aktionen belohnt und für schlechte bestraft wird (z.B. beim Training einer KI für ein Brettspiel).

:::{.callout-note title="Ein kleiner Grundriss (Ein Vortrag, den ich dazu mal gehalten habe)" collapse="true"}

<object data="Quellen/Lernalgorithmen.pdf" type="application/pdf" width="100%" height="600px">
    <p>Ihr Browser unterstützt keine eingebetteten PDFs. Sie können es stattdessen <a href="Quellen/Lernalgorithmen.pdf">hier herunterladen</a>.</p>
</object>

Bei Fragen zu dem Vortrag, frag mich gerne :D

:::

Für weiteres: [@sep_ml; @wiki_machinelearning]

### Deep Learning

Deep Learning ist ein Teilgebiet des maschinellen Lernens, das besonders **tiefe** (*im Sinne von vielen Lagen hintereinander*) neuronale Netze verwendet. Diese Tiefe ermöglicht es dem Modell, sehr komplexe und hierarchische Merkmale aus den Daten zu lernen.

-   **Merkmalshierarchie:** Die ersten Schichten erkennen einfache Merkmale (z.B. Kanten in einem Bild), während tiefere Schichten diese zu komplexeren Konzepten (z.B. Augen, Gesichter) zusammensetzen.
-   **Anwendungen:** Fast alle modernen Durchbrüche wie Bilderkennung, Sprachübersetzung (Google Translate) und selbstfahrende Autos basieren auf Deep Learning. LLMs sind ebenfalls eine Form des Deep Learning.

Für weiteres: [@lecun2015deep; @wiki_deeplearning]

### Neuronale Netze

Neuronale Netze sind das Herzstück des Deep Learning. Sie sind von der Struktur des menschlichen Gehirns inspiriert und bestehen aus miteinander verbundenen "Neuronen", die in Schichten (Layern) angeordnet sind.

-   **Aufbau:** Jedes Neuron empfängt Signale, verarbeitet sie und gibt ein eigenes Signal an die nächste Schicht weiter. Die Verbindungen zwischen den Neuronen haben "Gewichte", die im Lernprozess angepasst werden.
-   **Funktion:** Durch die Anpassung dieser Gewichte lernt das Netz, komplexe Muster in den Daten zu erkennen – zum Beispiel die Pixelmuster, die eine Katze auf einem Bild ausmachen.

Ein fantastisches Video, das die Grundlagen visuell erklärt, ist von **3Blue1Brown**: [@youtube3blue1brownNN]
:::

## Anwendungsbereiche
Nachdem nun klarer ist, was KI ist und welche Ansätze es gibt, hier ein kurzer Blick auf die Anwendungsbereiche. Am bekanntesten sind derzeit sicherlich die **Large Language Models (LLMs)** wie ChatGPT. Aber KI steckt auch in vielen anderen Technologien, wie zum Beispiel in der **Gesichtserkennung** auf dem Smartphone oder in Überwachungskameras.

## Vertiefungsmöglichkeiten:  
Für alle, die tiefer einsteigen wollen, hier ein paar Empfehlungen. Diese YouTube-Videos werden oft auch von Dozenten an Universitäten empfohlen:

- Der Kanal **3Blue1Brown** ist generell eine Goldgrube für visuelle Erklärungen zu Mathe und Informatik.
- Spezifische Videos zum Thema:
  - [Was ist ein neuronales Netz?](https://www.youtube.com/watch?v=aircAruvnKk)
  - [Wie neuronale Netze lernen](https://www.youtube.com/watch?v=IHZwWFHWa-w)
  - [Der Attention-Mechanismus (Grundlage für Transformer)](https://www.youtube.com/watch?v=LPZh9BOjkQs)

Weitere Berichte und Prinzipien finden sich bei der OECD und Stanford: [@oecd_ai; @hai_aiindex]
 
