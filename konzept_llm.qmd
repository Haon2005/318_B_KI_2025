---
title: "LLM- das Grundkonzept"
---

_Besser als ich es erklären kann, wird es im Zweifel [hier](https://www.youtube.com/watch?v=LPZh9BOjkQs) von **3blue1brown** auf Youtube erklärt, aber ich werde mich mal dran versuchen._

## Was ist ein LLM?
Ein Large Language Model (LLM), ein großes Sprachmodell zu Deutsch, ist eine Art von künstlicher Intelligenz, die darauf trainiert ist, menschliche Sprache zu verstehen und zu erzeugen. Man kann es sich als ein extrem großes neuronales Netz vorstellen, das mit einer gigantischen Menge an Textdaten (wie Büchern und großen Teilen des Internets) trainiert wurde.
Das Hauptziel eines LLM ist es, auf eine Texteingabe (einen "Prompt") eine sinnvolle und kontextbezogene textliche Antwort zu generieren. Bekannte Beispiele sind die Modelle der GPT-Reihe (die hinter ChatGPT stehen), Googles Gemini oder Metas Llama.

## Wie funktioniert ein LLM
Die Funktionsweise eines LLM lässt sich vereinfacht in zwei Hauptphasen unterteilen: das **Training** und die **Anwendung** (auch Inferenz genannt).

1.  **Phase 1: Das Training (Lernphase)**
    -   **Daten:** Das Modell wird mit riesigen Mengen an Texten gefüttert.
    -   **Ziel:** Die Kernaufgabe während des Trainings ist simpel, aber wirkungsvoll: **"Sage das nächste Wort voraus."** Das Modell bekommt einen Satzanfang und versucht, das wahrscheinlichste nächste Wort zu erraten. 
    -   **Lernprozess:** Bei jeder falschen Vorhersage passt es seine internen Parameter an. Durch milliardenfache Wiederholung lernt es so Grammatik, Fakten, Zusammenhänge und sogar Argumentationsstile. Es entwickelt ein statistisches "Verständnis" von Sprache.

2.  **Phase 2: Die Anwendung (Inferenz)**
    -   **Eingabe:** Du gibst eine Frage oder einen Befehl ein (der "Prompt").
    -   **Generierung:** Basierend auf deinem Prompt und seinem Training berechnet das LLM das wahrscheinlichste erste Wort der Antwort.
    -   **Wort für Wort:** Dieses neue Wort wird an die bisherige Konversation angehängt, und der Prozess wiederholt sich: Das Modell berechnet das nächste wahrscheinlichste Wort, dann das übernächste und so weiter, bis eine vollständige Antwort entstanden ist.

Es ist also kein einfaches Nachschlagen in einer Datenbank, sondern ein kreativer, statistischer Prozess der Texterzeugung.

Um die Funktionsweise besser zu verstehen, solltest du dir die nächsten Kapitel durchlesen. Dort wird erklärt, wie ein LLM Wörter überhaupt mathematisch versteht (**Vektor-Embedding**) und wie es im Detail aufgebaut ist.

## Weiterführende Quellen
Eine komprimierte Übersicht über Large Language Models wird angeboten von [@naveed2024comprehensiveoverviewlargelanguage]