---
title: "LLM – Das Grundkonzept"
bibliography: literatur.bib
---

_Besser als ich es erklären kann, wird es im Zweifel [hier](https://www.youtube.com/watch?v=LPZh9BOjkQs) von **3blue1brown** auf YouTube erklärt, aber ich werde mich mal dran versuchen._

## Was ist ein LLM?
Ein Large Language Model (LLM), auf Deutsch ein großes Sprachmodell, ist eine Art von künstlicher Intelligenz, die darauf trainiert ist, menschliche Sprache zu verstehen und zu erzeugen. Man kann es sich als ein extrem großes neuronales Netz vorstellen, das mit einer gigantischen Menge an Textdaten (wie Büchern und großen Teilen des Internets) trainiert wurde.
Das Hauptziel eines LLM ist es, auf eine Texteingabe (einen "Prompt") eine sinnvolle und kontextbezogene textliche Antwort zu generieren. Bekannte Beispiele sind die Modelle der GPT-Reihe (die hinter ChatGPT stehen), Googles Gemini oder Metas Llama.

## Wie funktioniert ein LLM
Die Funktionsweise eines LLM lässt sich vereinfacht in zwei Hauptphasen unterteilen: das **Training** und die **Anwendung** (auch Inferenz genannt).

1.  **Phase 1: Das Training (Lernphase)**
    -   **Daten:** Das Modell wird mit riesigen Mengen an Texten gefüttert.
    -   **Ziel:** Die Kernaufgabe während des Trainings ist simpel, aber wirkungsvoll: **"Sage das nächste Wort voraus."** Das Modell bekommt einen Satzanfang und versucht, das wahrscheinlichste nächste Wort zu erraten. 
    -   **Lernprozess:** Bei jeder falschen Vorhersage passt es seine internen Parameter an. Durch milliardenfache Wiederholung lernt es so Grammatik, Fakten, Zusammenhänge und sogar Argumentationsstile. Es entwickelt ein statistisches "Verständnis" von Sprache.

2.  **Phase 2: Die Anwendung (Inferenz)**
    -   **Eingabe:** Du gibst eine Frage oder einen Befehl ein (der "Prompt").
    -   **Generierung:** Basierend auf deinem Prompt und seinem Training berechnet das LLM das wahrscheinlichste erste Wort der Antwort.
    -   **Wort für Wort:** Dieses neue Wort wird an die bisherige Konversation angehängt, und der Prozess wiederholt sich: Das Modell berechnet das nächste wahrscheinlichste Wort, dann das übernächste und so weiter, bis eine vollständige Antwort entstanden ist.

Die erste Phase ist hierbei wie bei jeder anderen Art des Maschinellen Lernens.  
Die zweite Phase hingegen ist besonders: Hier geht es darum, einen Text weiterzuschreiben. Für das LLM gibt es nämlich keinen "Chat", sondern nur einen einzigen, fortlaufenden Text. Unsichtbar für den Nutzer wird nach jeder Eingabe und vor jeder Ausgabe ein interner Erklärtext eingefügt, der dem Modell den Kontext gibt.

:::{.callout-tip title="Auch hierzu musste ich mal einen Vortrag in der Uni halten" collapse="true"}

Der Vortrag bzw. die Folien des Vortrags sind mehr oder weniger das ganze Kapitel in anderer Form (nicht nur dieses Unterkapitel, also evtl. erst im Nachhinein angucken :shrug:).

<object data="Quellen/Grundlagen Large Language Models.pdf" type="application/pdf" width="100%" height="600px">
    <p>Ihr Browser unterstützt keine eingebetteten PDFs. Sie können es stattdessen <a href="Quellen/Grundlagen Large Language Models.pdf">hier herunterladen</a>.</p>
</object>

:::

Um die Funktionsweise besser zu verstehen, solltest du dir die nächsten Kapitel durchlesen. Dort wird erklärt, wie ein LLM Wörter überhaupt mathematisch versteht (**Vektor-Embedding**) und wie es im Detail aufgebaut ist.

## Weiterführende Quelle
Eine komprimierte Übersicht über Large Language Models findet man bei [@naveed2024comprehensiveoverviewlargelanguage]
Eine sehr gute Seite, die einen kompletten Überblick über Transformer-Modelle inklusive Erklärungen bietet, ist [bbycroft.net/llm](https://bbycroft.net/llm). Diese Seite ist, ähnlich wie die aus dem Kapitel "Deterministisch vs. Probabilistisch", sehr zu empfehlen.